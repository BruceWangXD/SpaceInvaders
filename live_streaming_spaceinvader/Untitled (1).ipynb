{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ongoing-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pynput\n",
    "import serial\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pynput.keyboard import Listener\n",
    "import logging\n",
    "from scipy.io.wavfile import write\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "trained-regard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dev/cu.Bluetooth-Incoming-Port - n/a\n",
      "/dev/cu.BruceWongBeatsStudio3-W - n/a\n",
      "/dev/cu.BruceWongBeatsStudio3-S - n/a\n",
      "/dev/cu.usbmodem141101 - Arduino Leonardo\n"
     ]
    }
   ],
   "source": [
    "# use this to find ports\n",
    "from serial.tools import list_ports\n",
    "\n",
    "ports = list_ports.comports()\n",
    "for port in ports:\n",
    "    print(port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "upper-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read example data\n",
    "baudrate = 230400\n",
    "# cport = '/dev/cu.usbmodem142301'  # set the correct port before you run it\n",
    "cport = \"/dev/cu.usbmodem141101\"\n",
    "#cport = '/dev/tty.usbmodem141101'  # set the correct port before run it\n",
    "ser = serial.Serial(port=cport, baudrate=baudrate)    \n",
    "# take example data\n",
    "inputBufferSize = 10000 # 20000 = 1 second\n",
    "ser.timeout = inputBufferSize/20000.0  # set read timeout\n",
    "#ser.set_buffer_size(rx_size = inputBufferSize)\n",
    "data = read_arduino(ser,inputBufferSize)\n",
    "# data_plot = process_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "realistic-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_arduino(ser,inputBufferSize):\n",
    "#    data = ser.readline(inputBufferSize)\n",
    "    data = ser.read(inputBufferSize)\n",
    "    out =[(int(data[i])) for i in range(0,len(data))]\n",
    "    return out\n",
    "# def read_arduinbro(wav_array, inputBufferSize, k):\n",
    "# #    data = ser.readline(inputBufferSize)\n",
    "#     if inputBufferSize*(k+1) < len(wav_array):\n",
    "#         data = wav_array[(inputBufferSize*(k)):(inputBufferSize*(k+1))]\n",
    "#     else:\n",
    "#         data = wav_array[(inputBufferSize*(k))::]\n",
    "#     return np.flip(data)\n",
    "def process_data(data):\n",
    "    data_in = np.array(data)\n",
    "    result = []\n",
    "    i = 1\n",
    "    while i < len(data_in)-1:\n",
    "        if data_in[i] > 127:\n",
    "            # Found beginning of frame\n",
    "            # Extract one sample from 2 bytes\n",
    "            intout = (np.bitwise_and(data_in[i],127))*128\n",
    "            i = i + 1\n",
    "            intout = intout + data_in[i]\n",
    "            result = np.append(result,intout)\n",
    "        i=i+1\n",
    "    return np.flip(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "speaking-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_event(arr, samprate, downsample_rate=10, window_size_seconds=0.1, max_loops=10): \n",
    "    arr_ds = arr[0::downsample_rate]\n",
    "    \n",
    "    \n",
    "    \n",
    "    fs = samprate/downsample_rate\n",
    "    dt = 1/fs\n",
    "    t = np.arange(0, (len(arr_ds)*dt), dt)\n",
    "\n",
    "    # Smooth wave\n",
    "    window_length = int(window_size_seconds*samprate/downsample_rate + 1)\n",
    "#     print('window length:')\n",
    "#     print(window_length)\n",
    "#     print('array shape')\n",
    "#     print(np.shape(arr_ds))\n",
    "\n",
    "    filtered_arr = signal.savgol_filter(arr_ds, window_length, 1)\n",
    "\n",
    "    # Indices of positive maxima\n",
    "    max_locs = np.array(signal.argrelextrema(filtered_arr, np.greater)[0])\n",
    "    max_vals = filtered_arr[max_locs]\n",
    "    max_locs = max_locs[max_vals > 0]\n",
    "    \n",
    "    # Indices of negative minima\n",
    "    min_locs = np.array(signal.argrelextrema(filtered_arr, np.less)[0])\n",
    "    min_vals = filtered_arr[min_locs]\n",
    "    min_locs = min_locs[min_vals < 0]\n",
    "    \n",
    "    # Appended indices\n",
    "    max_min_locs = np.append(max_locs, min_locs)\n",
    "    \n",
    "    # Values of above indices\n",
    "    max_min_values = filtered_arr[max_min_locs]\n",
    "    \n",
    "    # Absolute value of those values\n",
    "    abs_max_min_values = np.abs(max_min_values)\n",
    "    \n",
    "    # A vector with a length equal to the number of minimums: all '-1' to say minimum\n",
    "    numMin = [-1]*len(min_locs)\n",
    "    # A vector with a length equal to the number of maximums: all '1' to say maximum\n",
    "    numMax = [1]*len(max_locs)\n",
    "    \n",
    "    # Vector same size as max_min_values with first half being maximums and second half being minimums\n",
    "    isMin = np.append(numMax, numMin)\n",
    "    \n",
    "    # Stack the three vectors\n",
    "    val_and_idx = np.vstack([abs_max_min_values, max_min_locs, isMin])\n",
    "    \n",
    "    # Sort the magnitudes of the extrema in descending order (-1 indicates descending)\n",
    "    val_and_idx_sorted = val_and_idx[ :, (-1*val_and_idx[0]).argsort()]\n",
    "\n",
    "    classificationFound = False\n",
    "    \n",
    "    # We will continue looping until we have an appropriate classification. This relies on having the extrema INTERCHANGE between max and min (no two min right next to eachother)\n",
    "    loops = 0\n",
    "    while not classificationFound and loops < max_loops:\n",
    "        \n",
    "        # Take the top three magnitudes\n",
    "        top_3 = val_and_idx_sorted[:, 0:3]\n",
    "        \n",
    "        # Sort according to the indices of those values\n",
    "        top_3_sorted = top_3[ :, top_3[1].argsort()]\n",
    "        \n",
    "        # Break if we run out of turning points\n",
    "        if top_3_sorted.shape != (3, 3):\n",
    "            return \"_\"\n",
    "        \n",
    "        # If two min or two max occur one after the other, we know we have an inappropriate result so we delete one of those doubled min/max\n",
    "        if top_3_sorted[2, 0]*top_3_sorted[2, 1] > 0:\n",
    "            val_and_idx_sorted = np.delete(val_and_idx_sorted, 1, 1)\n",
    "        elif top_3_sorted[2, 1]*top_3_sorted[2, 2] > 0:\n",
    "            val_and_idx_sorted = np.delete(val_and_idx_sorted, 2, 1)\n",
    "        else:\n",
    "            classificationFound = True\n",
    "        \n",
    "        loops += 1\n",
    "    \n",
    "    if np.sum(top_3_sorted[2, :]) == -1:\n",
    "        return 'L'\n",
    "    elif np.sum(top_3_sorted[2, :]) == 1:\n",
    "        return 'R'\n",
    "    else:\n",
    "        return \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "treated-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def streaming_classifier(\n",
    "    wav_array, # Either the array from file (or ser if live = True)\n",
    "    samprate,\n",
    "    window_size = 1.5, # Total detection window [s]\n",
    "    N_loops_over_window = 15, # implicitly defines buffer to be 1/x of the window\n",
    "    hyp_detection_buffer_end = 0.3, # seconds - how much time to shave off end of the window in order to define the middle portion\n",
    "    hyp_detection_buffer_start = 0.7, # seconds - how much time to shave off start of the window in order to define the middle portion\n",
    "    hyp_event_smart_threshold_window = 5, # The length of the calibration period to define the threshold\n",
    "    hyp_calibration_statistic_function = lambda x: np.max(x) - np.min(x), # Function that calculates the calibration statistic\n",
    "    hyp_test_statistic_function = lambda x: np.max(x) - np.min(x), # Function that calculates the test statistic\n",
    "    hyp_event_smart_threshold_factor = 0.5, # The scale factor of the calibration range that will become the threshold\n",
    "    hyp_event_history = 5, # How many historical event detection results are kept in memory (whether the test criteria failed or passed)\n",
    "    hyp_consecutive_triggers = 3, # How many threshold triggers need to occur in a row for an event to be called\n",
    "    hyp_consecutive_reset = 1, # How many threshold failures need to occur in a row for the classifier to be primed for a new event\n",
    "    hyp_timeout = 10,\n",
    "    total_time = None,  # max time. If none, it goes forever!\n",
    "    plot = False, # Whether to plot the livestream data\n",
    "    store_events = False, # Whether to return the classification window array for debugging purposes\n",
    "    verbose=False, # lol\n",
    "    live = False, # Whether we're\n",
    "    timeout = False\n",
    "):\n",
    "\n",
    "    \n",
    "    \n",
    "    if total_time is None:\n",
    "        try:\n",
    "            total_time = len(wav_array)/samprate\n",
    "        except:\n",
    "            total_time = 1000000 # Just a large number\n",
    "    if store_events:\n",
    "        predictions_storage = []\n",
    "    \n",
    "    predictions = \"\"\n",
    "    predictions_timestamps = []\n",
    "\n",
    "    \n",
    "    # Initialise variables\n",
    "    inputBufferSize = int(window_size/N_loops_over_window * samprate)\n",
    "    N_loops =(total_time*samprate)//inputBufferSize  # len(wav_array)//inputBufferSize \n",
    "    T_acquire = inputBufferSize/samprate    # length of time that data is acquired for \n",
    "    N_loops_over_window = window_size/T_acquire    # total number of loops to cover desire time window\n",
    "\n",
    "\n",
    "    # Initialise plot\n",
    "    if plot:\n",
    "        min_y = -200 #np.min(wav_array)\n",
    "        max_y = 200 #np.max(wav_array)\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(1,1,1)\n",
    "        plt.ion()\n",
    "        fig.show()\n",
    "        fig.canvas.draw()\n",
    "\n",
    "\n",
    "    # Hyperparameter conversions\n",
    "    hyp_detection_buffer_start_ind = int(round(hyp_detection_buffer_start * samprate))\n",
    "    hyp_detection_buffer_end_ind = int(round(hyp_detection_buffer_end * samprate))\n",
    "    \n",
    "    \n",
    "    # Initialise Calibration\n",
    "    calibrate = True\n",
    "    N_loops_calibration = hyp_event_smart_threshold_window//(window_size/N_loops_over_window)\n",
    "    \n",
    "\n",
    "    # Initialise Event History\n",
    "    event_history = np.array([False]*hyp_event_history)\n",
    "    primed = True\n",
    "\n",
    "    for k in range(0,int(N_loops)):\n",
    "        \n",
    "        # Simulate stream\n",
    "        if live:\n",
    "            data = read_arduino(wav_array,inputBufferSize)\n",
    "            data_temp = process_data(data)\n",
    "        else:\n",
    "            data_temp = read_arduino(wav_array, inputBufferSize)\n",
    "\n",
    "\n",
    "        if k < N_loops_over_window:\n",
    "            if k==0:\n",
    "                data_cal = data_temp\n",
    "                data_plot = data_temp\n",
    "            else:\n",
    "                data_plot = np.append(data_temp, data_plot)\n",
    "                if calibrate:\n",
    "                    data_cal = np.append(data_temp, data_cal)\n",
    "            continue\n",
    "        else:\n",
    "            data_plot = np.roll(data_plot,len(data_temp))\n",
    "            data_plot[0:len(data_temp)] = data_temp\n",
    "            \n",
    "            if calibrate:\n",
    "                data_cal = np.append(data_temp,data_cal)\n",
    "\n",
    "                if (k > N_loops_calibration):\n",
    "                    st_range = hyp_calibration_statistic_function(data_cal)\n",
    "                    hyp_event_threshold = st_range*hyp_event_smart_threshold_factor\n",
    "                    with open(\"./print.txt\", \"a\") as file:\n",
    "                        file.write(str(hyp_event_threshold)+',')\n",
    "                    calibrate = False\n",
    "                continue\n",
    "                \n",
    "\n",
    "\n",
    "        ### CLASSIFIER ###\n",
    "        \n",
    "        ## EVENT DETECTION ##\n",
    "\n",
    "        interval = data_plot[hyp_detection_buffer_start_ind:-hyp_detection_buffer_end_ind] # Take middle part of window\n",
    "\n",
    "\n",
    "    #     test_stat = np.sum(interval[0:-1] * interval[1::] <= 0) # Calculate test stat (zero crossings) \n",
    "        test_stat = hyp_test_statistic_function(interval) # Calculate test stat (defaults to range) \n",
    "        # test_stat = test_stat/(len(interval)/samprate) # convert to crossings per second\n",
    "\n",
    "        hyp_event_threshold = 600\n",
    "        test_stat = np.max(interval)\n",
    "        is_event = (test_stat > hyp_event_threshold) # Test threshold\n",
    "        print(is_event)\n",
    "        ## KEEP HISTORY ##\n",
    "\n",
    "        event_history[1::] = event_history[0:-1]\n",
    "        event_history[0] = is_event\n",
    "\n",
    "\n",
    "        ## Classification\n",
    "\n",
    "        if np.all(event_history[0:hyp_consecutive_triggers]) and primed:\n",
    "            prediction = classify_event(data_plot, samprate)\n",
    "            \n",
    "            \n",
    "            print(f\"CONGRATULATIONS, ITS AN {prediction}!\") if verbose else None\n",
    "\n",
    "            if store_events:\n",
    "                predictions_storage.append(data_plot)\n",
    "            \n",
    "            predictions += prediction\n",
    "            \n",
    "            \n",
    "            end_time = round(k*inputBufferSize/samprate, 2)\n",
    "            start_time = round(end_time - window_size, 2)\n",
    "            predictions_timestamps.append((start_time, end_time))\n",
    "            \n",
    "            timer = hyp_timeout\n",
    "\n",
    "            primed = False\n",
    "        else:\n",
    "            timer=hyp_timeout#gai\n",
    "        \n",
    "        \n",
    "        if not timeout:\n",
    "            if np.all(~event_history[0:hyp_consecutive_reset]):\n",
    "                primed = True\n",
    "        else:\n",
    "            if timer < 0:\n",
    "                primed = True\n",
    "\n",
    "        timer -= 1\n",
    "\n",
    "        ## PLOT ###\n",
    "\n",
    "        if plot:\n",
    "            t = (min(k+1,N_loops_over_window))*inputBufferSize/samprate*np.linspace(0,1,(data_plot).size)\n",
    "            ax1.clear()\n",
    "            # Debugging Annotations\n",
    "            if np.all(event_history[0:hyp_consecutive_triggers]) and timer >0:\n",
    "                ax1.annotate(f\"ITS AN {prediction}!!!\", (window_size/2, max_y-50))\n",
    "            \n",
    "            ax1.annotate(f\"{event_history}\", (window_size/2, max_y-70))\n",
    "            ax1.set_xlim(0, window_size)\n",
    "            ax1.set_ylim(min_y, max_y)\n",
    "            plt.xlabel('time [s]')\n",
    "            ax1.plot(t,data_plot)\n",
    "            fig.canvas.draw()    \n",
    "            plt.show()\n",
    "    \n",
    "    if store_events:\n",
    "        return predictions, predictions_timestamps, predictions_storage\n",
    "    else:\n",
    "        return predictions, predictions_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "earned-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #hyp_event_threshold\n",
    "\n",
    "\n",
    "# def streaming_classifier(\n",
    "#     wav_array, # Either the array from file (or ser if live = True)\n",
    "#     samprate,\n",
    "#     primed,\n",
    "#     window_size = 1.5, # Total detection window [s]\n",
    "#     N_loops_over_window = 15, # implicitly defines buffer to be 1/x of the window\n",
    "#     hyp_detection_buffer_end = 0.3, # seconds - how much time to shave off end of the window in order to define the middle portion\n",
    "#     hyp_detection_buffer_start = 0.7, # seconds - how much time to shave off start of the window in order to define the middle portion\n",
    "#     hyp_event_smart_threshold_window = 5, # The length of the calibration period to define the threshold\n",
    "#     hyp_calibration_statistic_function = lambda x: np.max(x) - np.min(x), # Function that calculates the calibration statistic\n",
    "#     hyp_test_statistic_function = lambda x: np.max(x) - np.min(x), # Function that calculates the test statistic\n",
    "#     hyp_event_smart_threshold_factor = 0.5, # The scale factor of the calibration range that will become the threshold\n",
    "#     hyp_event_history = 5, # How many historical event detection results are kept in memory (whether the test criteria failed or passed)\n",
    "#     hyp_consecutive_triggers = 3, # How many threshold triggers need to occur in a row for an event to be called\n",
    "#     hyp_consecutive_reset = 1, # How many threshold failures need to occur in a row for the classifier to be primed for a new event\n",
    "#     hyp_timeout = 10,\n",
    "#     total_time = 60,  # max time. If none, it goes forever!\n",
    "#     plot = False, # Whether to plot the livestream data\n",
    "#     store_events = False, # Whether to return the classification window array for debugging purposes\n",
    "#     verbose=False, # lol\n",
    "#     live = False, # Whether we're\n",
    "#     timeout = False\n",
    "# ):\n",
    "\n",
    "    \n",
    "    \n",
    "#     predictions = \"\"\n",
    "#     max_time = 60\n",
    "#     # Initialise variables\n",
    "#     inputBufferSize = int(window_size/N_loops_over_window * samprate)\n",
    "#     N_loops =(total_time*samprate)//inputBufferSize  # len(wav_array)//inputBufferSize \n",
    "#     T_acquire = inputBufferSize/samprate    # length of time that data is acquired for \n",
    "#     N_max_loops = max_time/T_acquire    # total number of loops to cover desire time window\n",
    "#     N_loops_over_window = window_size/T_acquire    # total number of loops to cover desire time window\n",
    "\n",
    "\n",
    "\n",
    "#     # Hyperparameter conversions\n",
    "#     hyp_detection_buffer_start_ind = int(round(hyp_detection_buffer_start * samprate))\n",
    "#     hyp_detection_buffer_end_ind = int(round(hyp_detection_buffer_end * samprate))\n",
    "    \n",
    "    \n",
    "#     for k in range(0,int(N_loops)):\n",
    "#         data = read_arduino(ser,inputBufferSize)\n",
    "#         data_temp = process_data(data)\n",
    "\n",
    "\n",
    "#         if k <= N_max_loops:\n",
    "#             if k==0:\n",
    "#                 data_plot = data_temp\n",
    "#             else:\n",
    "#                 data_plot = np.append(data_temp,data_plot)\n",
    "#         else:\n",
    "#             data_plot = np.roll(data_plot,len(data_temp))\n",
    "#             data_plot[0:len(data_temp)] = data_temp\n",
    "\n",
    "\n",
    "#         ### CLASSIFIER ###\n",
    "\n",
    "#         ## EVENT DETECTION ##รท\n",
    "#         print(data_plot)\n",
    "#         interval = data_plot[hyp_detection_buffer_start_ind:-hyp_detection_buffer_end_ind] # Take middle part of window\n",
    "#         print(interval)\n",
    "        \n",
    "#         test_stat = hyp_test_statistic_function(interval) # Calculate test stat (defaults to range) \n",
    "#     #     print(test_stat)\n",
    "#         hyp_event_threshold = 100\n",
    "#         is_event = (test_stat > hyp_event_threshold) # Test threshold\n",
    "#     #     print(is_event)\n",
    "#     #     if is_event:\n",
    "#     #         print('yay')\n",
    "\n",
    "#         if not is_event:\n",
    "#             primed = True\n",
    "\n",
    "\n",
    "#         ## Classification\n",
    "\n",
    "#         if primed and is_event:\n",
    "\n",
    "#             prediction = classify_event(data_plot, samprate)\n",
    "\n",
    "\n",
    "#             print(f\"CONGRATULATIONS, ITS AN {prediction}!\") if verbose else None\n",
    "\n",
    "#             if store_events:\n",
    "#                 predictions_storage.append(data_plot)\n",
    "\n",
    "#             predictions += prediction\n",
    "\n",
    "\n",
    "#             end_time = round(k*inputBufferSize/samprate, 2)\n",
    "#             start_time = round(end_time - window_size, 2)\n",
    "#             predictions_timestamps.append((start_time, end_time))\n",
    "\n",
    "#             timer = hyp_timeout\n",
    "\n",
    "#             primed = False\n",
    "\n",
    "\n",
    "# #     print(predictions)\n",
    "#     return predictions, primed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         ## PLOT ###\n",
    "\n",
    "# #         if plot:\n",
    "# #             t = (min(k+1,N_loops_over_window))*inputBufferSize/samprate*np.linspace(0,1,(data_plot).size)\n",
    "# #             ax1.clear()\n",
    "# #             # Debugging Annotations\n",
    "# #             if np.all(event_history[0:hyp_consecutive_triggers]) and timer >0:\n",
    "# #                 ax1.annotate(f\"ITS AN {prediction}!!!\", (window_size/2, max_y-50))\n",
    "            \n",
    "# #             ax1.annotate(f\"{event_history}\", (window_size/2, max_y-70))\n",
    "# #             ax1.set_xlim(0, window_size)\n",
    "# #             ax1.set_ylim(min_y, max_y)\n",
    "# #             plt.xlabel('time [s]')\n",
    "# #             ax1.plot(t,data_plot)\n",
    "# #             fig.canvas.draw()    \n",
    "# #             plt.show()\n",
    "    \n",
    "# #     if store_events:\n",
    "# #         return predictions, predictions_timestamps, predictions_storage\n",
    "# #     else:\n",
    "# #         return predictions, predictions_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "mineral-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-5664e1257f98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# prediction = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstreaming_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-b17947bedd9b>\u001b[0m in \u001b[0;36mstreaming_classifier\u001b[0;34m(wav_array, samprate, window_size, N_loops_over_window, hyp_detection_buffer_end, hyp_detection_buffer_start, hyp_event_smart_threshold_window, hyp_calibration_statistic_function, hyp_test_statistic_function, hyp_event_smart_threshold_factor, hyp_event_history, hyp_consecutive_triggers, hyp_consecutive_reset, hyp_timeout, total_time, plot, store_events, verbose, live, timeout)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mdata_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mdata_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_arduino\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputBufferSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-a2189b2e6573>\u001b[0m in \u001b[0;36mread_arduino\u001b[0;34m(ser, inputBufferSize)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_arduino\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputBufferSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#    data = ser.readline(inputBufferSize)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputBufferSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/serial/serialposix.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                 \u001b[0mready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_abort_read_r\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_abort_read_r\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_abort_read_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "primed = True\n",
    "# prediction = []\n",
    "while True:\n",
    "    prediction, primed = streaming_classifier(ser, 10000, primed)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-barcelona",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-richmond",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
