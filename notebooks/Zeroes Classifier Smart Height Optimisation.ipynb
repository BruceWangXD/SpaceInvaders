{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import wave, struct\n",
    "from copy import deepcopy\n",
    "from weighted_levenshtein import lev\n",
    "import time\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "from Classifier.load_data import load_training_data\n",
    "\n",
    "from Classifier.plot_data import plot_labelled_wave, plot_predictions, plot_detection_errors\n",
    "\n",
    "from Classifier.classifier import streaming_classifier, zeroes_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['left-middle-right-middle#2', 'left-middle-right-middle', 'left-middle-right-steph', 'left-middle-right-steph2', 'left-middle', 'right-middle']) dict_keys(['left-middle-right-middle#2', 'left-middle-right-middle', 'left-middle-right-steph', 'left-middle-right-steph2', 'left-middle', 'right-middle'])\n",
      "c:\\Users\\darap\\Documents\\School\\University\\2021, Sem. 1\\DATA3888\\Aqua10\\Classifier\\load_data.py:68: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  labels_dat = pd.read_csv(path+file, sep=\",\\t\", skiprows=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "waves, labels, samprate = load_training_data(path = \"/Users/darap/Documents/School/University/2021, Sem. 1/DATA3888/Aqua10/Datasets/Good Data - Sandeep no errors/\",\n",
    "                       scale_factor= 512/(2**13 - 1),\n",
    "                       blacklist = [\"blink\", \"different\", \"fast\", \"slow\", \"eyebrow\", \"left-right-middle-sandeep\", \"left-right-middle-marina\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\nAverage: 0.0\ndone\n"
     ]
    }
   ],
   "source": [
    "# ASSUMES THAT HEIGHT_THRESHOLD AND CONSECUTIVE_SAMPLES_THRESHOLD ARE INDEPENDENT\n",
    "\n",
    "# Set parameters such that event detection window lands in the middle of the signal\n",
    "\n",
    "hyp_event_smart_threshold_window = 5\n",
    "hyp_event_smart_threshold_factor = 5\n",
    "\n",
    "hyp_detection_buffer_end = 0.6\n",
    "hyp_detection_buffer_start = 0.2\n",
    "\n",
    "\n",
    "det_window = 0.6432\n",
    "\n",
    "window_size = det_window + hyp_detection_buffer_end + hyp_detection_buffer_start\n",
    "\n",
    "N_loops_over_window = 15\n",
    "\n",
    "buffer_size = window_size/N_loops_over_window\n",
    "\n",
    "hyp_consecutive_triggers = int(np.ceil(det_window/buffer_size))\n",
    "#print(hyp_consecutive_triggers)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(len(waves), 1)\n",
    "# fig.set_size_inches(15, 3*len(waves))\n",
    "\n",
    "\n",
    "acc_list = []\n",
    "\n",
    "#CONSEC OPTIMISATION\n",
    "\n",
    "for i, key in enumerate(waves):\n",
    "    predictions, predictions_timestamps, predictions_storage = streaming_classifier(\n",
    "        waves[key], # Either the array from file (or ser if live = True)\n",
    "        samprate,\n",
    "        classifier = zeroes_classifier, \n",
    "        using_zeroes_classifier = True,\n",
    "        use_smart_hyp_zeroes_height_threshold = True,\n",
    "        zeroes_height_threshold = 10,\n",
    "        zeroes_consec_threshold = 0.2,\n",
    "        window_size = window_size, # Total detection window [s]\n",
    "        N_loops_over_window = N_loops_over_window, # implicitly defines buffer to be 1/x of the window\n",
    "        hyp_detection_buffer_end = hyp_detection_buffer_end, # seconds - how much time to shave off end of the window in order to define the middle portion\n",
    "        hyp_detection_buffer_start = hyp_detection_buffer_start, # seconds - how much time to shave off start of the window in order to define the middle portion\n",
    "        hyp_event_smart_threshold_window = hyp_event_smart_threshold_window, # The length of the calibration period to define the threshold\n",
    "        hyp_calibration_statistic_function = lambda x: np.max(x) - np.min(x), # Function that calculates the calibration statistic\n",
    "        hyp_test_statistic_function = lambda x: np.max(x) - np.min(x), # Function that calculates the test statistic\n",
    "        hyp_event_smart_threshold_factor = hyp_event_smart_threshold_factor, # The scale factor of the calibration range that will become the threshold\n",
    "        hyp_event_history = hyp_consecutive_triggers+1, # How many historical event detection results are kept in memory (whether the test criteria failed or passed)\n",
    "        hyp_consecutive_triggers = hyp_consecutive_triggers, # How many threshold triggers need to occur in a row for an event to be called\n",
    "        hyp_consecutive_reset = 1, # How many threshold failures need to occur in a row for the classifier to be primed for a new event\n",
    "        total_time = None,  # max time. If none, it goes forever!\n",
    "        plot = False, # Whether to plot the livestream data\n",
    "        store_events = True, # Whether to return the classification window array for debugging purposes\n",
    "        store_times = False, # To see how long classification takes\n",
    "        verbose = False, # lol\n",
    "        live = False, # Whether we're live\n",
    "        hyp_timeout = 10,\n",
    "        timeout = False)        \n",
    "\n",
    "    actuals = \"\".join(labels[key].label)\n",
    "\n",
    "    lev_dist = lev(actuals, predictions)\n",
    "    acc = abs(len(actuals) - lev_dist)/len(actuals)\n",
    "    acc_list.append(acc)\n",
    "\n",
    "print(acc_list)\n",
    "print(\"Average:\", np.mean(acc_list))\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "#     plot_predictions(waves[key], samprate, labels[key], predictions, predictions_timestamps, ax, i,\n",
    "#                      title=\"\", before_buffer = 0.7, after_buffer = 1, actual_alpha=0.0,\n",
    "#                      wave_alpha=1, pred_alpha = 0.5, miny = -100, maxy = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3810jvsc74a57bd0c4dc433831b506e0d25481c84a652fa4d2aed8e252441e22b25d2076b86b7e5b",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "c4dc433831b506e0d25481c84a652fa4d2aed8e252441e22b25d2076b86b7e5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}