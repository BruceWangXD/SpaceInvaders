{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Space Invaders Fun and Accessible with Brain-Computer Interfacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technological advancements such as gesture control, voice recognition, virtual and augmented reality are redefining gaming, advancing an already booming and competitive industry. The project detailed in this report is a redesigned version of Space Invaders, with the ship controlled using gestures, specifically left and right eye movements. Its development is motivated by the financial success of similarly advanced games such as Pokemon Go and without doubt, the original Space Invaders which was a technological wonder for its time. \n",
    "\n",
    "{numref}`flow` is a workflow diagram which illustrates the process undergone in the development of the product and how the Physics and Data Science disciplines worked as one unit. After performing a plethora of experiments, it was found that having the electrodes at least 3cm apart, performing fast eye movements and placing left and right markers for the user, generated a clean, noticeable, signal. Additionally, collecting data from all team members gave enough variation in the data to ensure our classifier is robust and general. \n",
    "\n",
    "Determining the event detection statistic that best distinguishes between regions of events and non-events involved evaluating the relationship between window size and contrast between the detection metric of said regions. The best performing detection method was found to be zero-crossings; the number of times the signal crosses the zero point (x-axis) per second, with an optimal window length of 0.35s. \n",
    "\n",
    "Similarly, determining the optimal classifier involved evaluating the relationship between window size and accuracy of the classifier. The most robust classifier was found to be the ‘one extrema classifier’ with 96% accuracy and optimal window size of 0.65s. This classifier smooths the signal using a savitzky-golay filter, then determines if the first turning point is a minimum or maximum. The time taken to execute each classifier (except for KNN) is negligible and thus did not contribute to our choice of classifier.\n",
    "\n",
    "Re-designing Space Invaders to be controlled using left and right eye movements is not solely useful as an entertaining game with potential commercial success. It is a tool that can act as a learning interface to teach individuals how gesture control performs (as the technology is inevitably integrated into our everyday lives) by using a familiar, nostalgic game such as space invaders. Additional applications include inclusive gaming for those with muscular impairments and building a foundation model for future projects to extend.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from scipy import signal\n",
    "from copy import deepcopy\n",
    "from catch22 import catch22_all\n",
    "import catch22\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from numba import njit\n",
    "from weighted_levenshtein import lev\n",
    "import struct\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Update this to point to the report folder\n",
    "# PATH = \"/Users/billydodds/Documents/Uni/DATA3888/Aqua10/Report/\"\n",
    "PATH = \"C:/Users/David/Documents/DATA3888/Aqua10/Report/\"\n",
    "# To run all computation, change to True. Otherwise, precomputed files will be loaded instead.\n",
    "compute_all = False\n",
    "# If running, ensure the following line is commented out. It disables plots for knitting to html purposes. \n",
    "%matplotlib agg\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(420) \n",
    "# Path to outputs folder\n",
    "OUT_PATH = PATH + \"report_outputs/\"\n",
    "# Path to data\n",
    "IN_PATH = PATH + \"data/\"\n",
    "# Path to other file dependencies\n",
    "DEP_PATH = PATH + \"requirements/other_files/\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation & Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the past two decades, profound advancements in technology such as facial recognition, gesture control, virtual assistants and other instances of machine learning have gradually been integrated into everyday life. With virtual reality worth over \\$21 billion alone {cite}`VR`, the gaming industry is evidently undergoing a similar transformation. Such financial success is reason enough to design and implement a game that is similarly controlled by one of these technological advancements. This project involves using gesture control, an instance of one of these technological advancements, to re-develop Space Invaders, the iconic 80’s game which grossed an equivalent of $13 billion {cite}`SpaceInvaders`. \n",
    "\n",
    "Our desired product is the nostalgic game of Space Invaders, with the spaceship  alternatively controlled by left and right eye movements. These movements are represented by signals generated by the Backyard Brains Spiker Box {cite}`BYB`. The creation of such a game is motivated by the financial success of games such as Pokemon Go which used augmented reality to re-develop the themes and goals of the popular video game series, Pokemon. Our target market is anyone interested in leading technologies and gaming, akin to PokemonGo’s and the original Space Invaders audience. A short survey was conducted and out of 33 people, 85% said they would be interested in this version of Space Invaders. This demonstrates potential commercial success with a remastered launch.\n",
    "\n",
    "The fundamental aim of this project is to accurately and efficiently detect eye movements, and distinguish between left and right signals. This becomes an arduous task if solely Physics or Data Science is used to implement this project. By integrating these disciplines, the task. The workflow diagram in {numref}`flow` visually explains the role of each discipline, and how the success of the final product depends on the integration of these sciences. In particular, the Physics discipline is responsible for the experimental design and collection of data, to generate a clean, noticeable signal that is representative of a larger group of people. The Data Science discipline is responsible for implementing code that reads this data, searches for the occurrence of a movement and classifies the specific gesture. Additionally, the integrated knowledge and skills of the Physics and Data Science disciplines led to designing and implementing a method that evaluates the performance of the code in terms of accuracy and efficiency of detection and classification. \n",
    "\n",
    "Thus, using the skills and knowledge of Physics and Data Science, a well-tested gesture controlled version of Space invaders can be developed.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation & Data Collection\n",
    "\n",
    "In reference to {numref}`flow`, the first step in the re-development of Space Invaders requires experimenting with the Spikerbox to collect data which is representative application of the game. The aim of experimentation is to define characteristic signal signatures (such as left and right eye movements) and determine how these change as physical aspects of the experimental design vary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physical experiments performed & Findings\n",
    "\n",
    "The following sections detail the plethora of experiments performed and specifically what each test was exploring.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General eye movements\n",
    "\n",
    "The first experiment is to determine if distinguishing between left and right eye movements is possible. Two electrodes were placed above the eyebrow of a team members eye and they were instructed to look forward. Then, the team member moved their eyes from the middle position, to the left or right, then immediately back to the middle-position.  (insert figure reference to signal graph) illustrates that while the signal shape of left and right eye movements appears the same, the polarity of the signals is inverted.\n",
    "\n",
    "#### Varying speed of eye movements\n",
    "With the same experimental set up, the team member is now instructed to vary the speed at which they look towards the left or right. It was found that when eye movements were too slow, the signal associated with looking from middle to the left became separated from that when looking from the left back to the middle. In fact, the differences between the signals had the same shape yet opposing polarity, much like that in the first experiment. However, with fast eye-movements, these two separate signals became one, yielding the same output as the first experiment.\n",
    "\n",
    "#### Varying distance of eye movements\n",
    "Now, the team member was asked to perform normal left-middle and right-middle eye movements such as in the first experiment, however, with each iteration they must look slightly further away from the middle position. The design of this experiment involved placing objects equally distant apart which acted as targets to look. It was found that if the eyes movement a small distance away from the middle position, a signal was barely detecable. This distance was not quantified, as we will see it is completely dependent on the individual performing the experiment. As the eyes moved further away from the beggining position, the amplitude of the signal grew accordingly. \n",
    "\n",
    "#### Electrode Placement\n",
    "The only experimental feature that is now different to the original experiment is the configuration of the electrode placements. It was found that placing the electrode vertically across tehe eye as opposed to horizontally no longer generates a distinguishabel signal for aleft and right eye movements. Instead, the best movement associated with this placement is up and down.\n",
    "\n",
    "Additionally, altering the distance between the electrode placement was tested about found that electrodes placed much closer than arounf 3cm to each other failed to generate a noticable, distinguishable signal with left and right eye movements.\n",
    "\n",
    "#### Changing Individual & Changing Boxes\n",
    "As experimental equipment was swapped, such as the SpikerBox itself, electrodes and connecting wires, or there there is a new team member collecting the data, the dignal generated was subject to change. Such changes included variation in noise, signal amplitude and in worst cases a completely different signal signature in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immediate Implications of Findings \n",
    "These are just things which we can immediately adapt our experimental design to witout even needing evaluation from test stats, classifiers etc. (i.e. this is the loop at the top of the workflow diagram under 'adapt experimental design')\n",
    "\n",
    "- may require some kind of normalisation to address the changing threshold of the signal\n",
    "- electrode placement that's too close can cause signal to disappear\n",
    "- touching/fiddling with any electrodes affects the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Collection of Data\n",
    "We have prepared 8 wave files (.wav) to the following specifications:\n",
    "- 50 seconds in length\n",
    "- First 5 seconds is a calibration period - no movements performed\n",
    "- A sequence of left and right movements are performed for the remaining 45 seconds\n",
    "- Each file is accompanied with a labels textfile (.txt) containing the timestamps and labels of every event in the wavefile. '1' corresponds to a left eye movement, and '2' corresponds to a right eye movement.\n",
    "- Each .wav file has a range of [0, 1024], but are centred to [-512, 512] within the `load_data` function defined below.\n",
    "\n",
    "Two of the eight files were randomly selected as the test set, and the rest were assigned to the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/David/Documents/DATA3888/Aqua10/Report/data/data6.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a8397ba8da66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Training Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m waves, labels = load_data(\n\u001b[0m\u001b[1;32m     27\u001b[0m     IN_PATH, training_files, scale_factor = 1, shift_factor = -512)\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a8397ba8da66>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path, fnames, scale_factor, shift_factor)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Load in wave file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0msamprate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mwav_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav_array\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mwav_array\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mshift_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/io/wavfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(filename, mmap)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mmmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/David/Documents/DATA3888/Aqua10/Report/data/data6.wav'"
     ]
    }
   ],
   "source": [
    "def load_data(path, fnames, scale_factor = 1, shift_factor = -512):\n",
    "    waves = {}\n",
    "    labels = {}\n",
    "    for file in fnames:\n",
    "        # Load in wave file\n",
    "        samprate, wav_array = wavfile.read(path+file+\".wav\")\n",
    "        wav_array = wav_array*scale_factor\n",
    "        wav_array += shift_factor\n",
    "        waves[file] = wav_array\n",
    "        # Load in label file\n",
    "        labels_dat = pd.read_csv(path+file+\".txt\", sep=\",\\t\", skiprows=1)\n",
    "        labels_dat.columns = [\"label\", \"time\"]\n",
    "        labels_dat.label = [\"L\" if label == 1 else \"R\" for label in labels_dat.label]\n",
    "        labels[file] = labels_dat\n",
    "    print(f\"Successfully loaded {len(waves)} wavefiles:\")\n",
    "    print(\"\\n\".join(sorted(waves.keys())))\n",
    "    return waves, labels\n",
    "\n",
    "fnames = [\"data1\", \"data2\", \"data3\", \"data4\", \"data5\", \"data6\", \"data7\", \"data8\"]\n",
    "\n",
    "# Randomly select two files for the test set, remainder as training\n",
    "test_files = np.random.choice(fnames, 2, replace=False)\n",
    "training_files = list(set(fnames) - set(test_files))\n",
    "\n",
    "# Training Data\n",
    "waves, labels = load_data(\n",
    "    IN_PATH, training_files, scale_factor = 1, shift_factor = -512)\n",
    "\n",
    "# Test Data\n",
    "test_waves, test_labels = load_data(\n",
    "    IN_PATH, test_files, scale_factor = 1, shift_factor = -512)\n",
    "\n",
    "# Define Sample Rate: 10,000 Hz\n",
    "samprate = 10_000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert the singular timestamps in the labels dataframe to the time interval of the entire event. There was a minor data quality issue with some of the timestamps which caused some files to have slightly shifted timestamps. To fix this, we went through and manually defined the interval for each file (the time to add before and after the timestamp to get the desired interval). We did this once to encompass the entire wave signal, and another time to only cover the first hump of the signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1,
     13
    ],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# First hump\n",
    "time_buffers_hump = {\n",
    "    \"data1\":(-0.3, 0.55),\n",
    "    \"data2\":(-0.3, 0.55),\n",
    "    \"data3\":(-0.3, 0.55),\n",
    "    \"data4\":(-0.5, 0.75),\n",
    "    \"data5\":(-0.5, 0.75),\n",
    "    \"data6\":(-0.5, 0.75),\n",
    "    \"data7\":(-0.5, 0.75),\n",
    "    \"data8\":(-0.5, 0.75)\n",
    "}\n",
    "\n",
    "# Whole wave\n",
    "time_buffers_whole = {\n",
    "    \"data1\":(-0.2, 1.15),\n",
    "    \"data2\":(-0.2, 1.15),\n",
    "    \"data3\":(-0.2, 1.15),\n",
    "    \"data4\":(-0.4, 1.35),\n",
    "    \"data5\":(-0.4, 1.35),\n",
    "    \"data6\":(-0.4, 1.35),\n",
    "    \"data7\":(-0.4, 1.35),\n",
    "    \"data8\":(-0.4, 1.35),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../report_outputs/flow.png\n",
    "---\n",
    "scale: 30%\n",
    "name: flow\n",
    "---\n",
    "Workflow diagram illustrating the process undergone by both Physics and Data Science disciplines in the re-developemnt of the game Space Invaders.\n",
    "```\n",
    "<!-- reference by {numref}`flow` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Algorithm Design\n",
    "\n",
    "First, we must design the basic structure of our streaming algorithm. The algorithm will consist of two parts, the first is event detection, and the second is classification. As the streaming data comes in, we will only keep a window of fixed length in memory, effectively behaving as a sliding window at the front of the stream. This window updates in discrete intervals of some *buffer length*, and we will deem this window the *classification window*. \n",
    "\n",
    "Within that classification window, we will fix another smaller window that slides along with the classification window. This subset of the classification window is what we will test an event criterion on, and is hence called the *detection window*. \n",
    "\n",
    "Each time the window is updated by the stream, the event criterion is tested on the detection window. To minimise false positives, that criterion will need to pass a set number of times, dictated by the `consecutive_event_triggers` parameter.\n",
    "\n",
    "Once the event criterion has passed `consecutive_event_triggers` times, we pass the classification window to the classifier algorithm and block the classifier from detecting another event. When the event criterion has failed `consecutive_nonevent_reset` times, we prime the streaming algorithm to predict events again. This is to stop the algorithm from detecting the same event twice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     2
    ],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Function that reads in the kth <inputBufferSize> sized segment of the array\n",
    "# Simulates streaming condition on recorded wavefiles.\n",
    "def read_arduinbro(wav_array, inputBufferSize, k):\n",
    "    if inputBufferSize*(k+1) < len(wav_array):\n",
    "        data = wav_array[(inputBufferSize*(k)):(inputBufferSize*(k+1))]\n",
    "    else:\n",
    "        data = wav_array[(inputBufferSize*(k))::]\n",
    "    return np.flip(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def streaming_classifier(\n",
    "        wav_array,                             # Either the array from file (or ser if live = True)\n",
    "        samprate,\n",
    "        classifier,\n",
    "        input_buffer_size_sec = 0.1,           # Buffer size in seconds\n",
    "        store_events = False,                  # Whether to return the classification window array for\n",
    "                                                   # debugging purposes\n",
    "        store_times = False,                   # Store time taken for each classification\n",
    "        live = False,\n",
    "        FIFO_filename = None,\n",
    "        create_FIFO_msg = None,\n",
    "\n",
    "        classifier_params = {},\n",
    "        classification_window_size_sec = 1.5,  # Total detection window [s]\n",
    "\n",
    "        calibration_window_size_sec = 5,       # The length of the calibration period to define the threshold\n",
    "        calibration_statistic_function = None, # Function that calculates the calibration statistic\n",
    "\n",
    "        detection_window_size_sec = 0.5,\n",
    "        detection_window_offset_sec = 0.5,\n",
    "        event_test_statistic_function = None,  # Function that calculates the test statistic\n",
    "        event_threshold_factor = 0.5,          # The scale factor of the calibration stat that will become\n",
    "                                                   # the threshold\n",
    "        flip_threshold = False,                # Threshold is a lower bound if true, upper bound if false\n",
    "        consecutive_event_triggers = 3,        # How many threshold triggers need to occur in a row for an \n",
    "                                                   # event to be called\n",
    "        consecutive_nonevent_reset = 1         # How many threshold failures need to occur in a row for the\n",
    "                                                   # classifier to be primed for a new event\n",
    "        ):\n",
    "\n",
    "    # Connect to fifo\n",
    "    if FIFO_filename is not None:\n",
    "        fifo = os.open(FIFO_filename, os.O_WRONLY)\n",
    "    \n",
    "    if store_events:\n",
    "        predictions_storage = []\n",
    "    if store_times:\n",
    "        classification_times = []\n",
    "    predictions = \"\"\n",
    "    predictions_timestamps = []\n",
    "\n",
    "    # Initialise variables\n",
    "    N_loops_over_window = classification_window_size_sec//input_buffer_size_sec\n",
    "    input_buffer_size = int(round(input_buffer_size_sec * samprate))\n",
    "    detection_window_offset = int(round(detection_window_offset_sec * samprate))\n",
    "    detection_window_size = int(round(detection_window_size_sec * samprate))\n",
    "    \n",
    "    # Initialise Calibration\n",
    "    calibrate = True\n",
    "    N_loops_calibration = calibration_window_size_sec//input_buffer_size_sec\n",
    "\n",
    "    # Initialise Event History\n",
    "    num_event_history = max(consecutive_event_triggers,\n",
    "                            consecutive_nonevent_reset) + 1 \n",
    "    event_history = np.array([False]*num_event_history)\n",
    "\n",
    "    # Determine length of stream\n",
    "    if live:\n",
    "        N_loops = np.inf\n",
    "    else:\n",
    "        total_time = len(wav_array)/samprate\n",
    "        N_loops = (total_time*samprate)//input_buffer_size\n",
    "\n",
    "    # Prime the classifier for new event\n",
    "    primed = True\n",
    "    \n",
    "    ### Start stream ###\n",
    "    k = 0\n",
    "    while k < N_loops:\n",
    "        if live:\n",
    "            data = read_arduino(wav_array,input_buffer_size)\n",
    "            data_temp = process_data(data)\n",
    "        else:\n",
    "            data_temp = read_arduinbro(wav_array, input_buffer_size, k)\n",
    "        if k < N_loops_over_window:\n",
    "            if k == 0:\n",
    "                data_cal = data_temp\n",
    "                data_window = data_temp\n",
    "            else:\n",
    "                data_window = np.append(data_temp, data_window)\n",
    "                if calibrate:\n",
    "                    data_cal = np.append(data_temp, data_cal)\n",
    "            k+=1\n",
    "            continue\n",
    "        else:\n",
    "            data_window = np.roll(data_window,len(data_temp))\n",
    "            data_window[0:len(data_temp)] = data_temp\n",
    "            if calibrate:\n",
    "                data_cal = np.append(data_temp,data_cal)\n",
    "                if (k > N_loops_calibration):\n",
    "                    cal_stat = calibration_statistic_function(data_cal)\n",
    "                    event_threshold = cal_stat*event_threshold_factor\n",
    "                    calibrate = False\n",
    "                k+=1\n",
    "                continue\n",
    "        # Event Detection\n",
    "        # Take detection window from classification window\n",
    "        \n",
    "        interval = data_window[detection_window_offset:(detection_window_offset + detection_window_size)] \n",
    "        test_stat = event_test_statistic_function(interval) # Calculate test stat \n",
    "                \n",
    "        # Test threshold\n",
    "        if flip_threshold:\n",
    "            is_event = (test_stat < event_threshold) \n",
    "        else:\n",
    "            is_event = (test_stat > event_threshold)\n",
    "        \n",
    "        # Record History\n",
    "        event_history[1::] = event_history[0:-1]\n",
    "        event_history[0] = is_event\n",
    "        \n",
    "        # if event, pass window to classifier\n",
    "        if np.all(event_history[0:consecutive_event_triggers]) and primed:\n",
    "            start = time.time_ns()\n",
    "            prediction = classifier(data_window, samprate, **classifier_params)\n",
    "            end = time.time_ns()\n",
    "            if store_times:\n",
    "                classification_times.append(end - start)\n",
    "            if store_events:\n",
    "                predictions_storage.append(data_window)\n",
    "                        \n",
    "            # Record prediction and time interval of event\n",
    "            predictions += prediction\n",
    "            end_time = round(k*input_buffer_size_sec, 2)\n",
    "            start_time = round(end_time - classification_window_size_sec, 2)\n",
    "            predictions_timestamps.append((start_time, end_time))\n",
    "\n",
    "            # Pipe it up\n",
    "            if FIFO_filename is not None:\n",
    "                msg = create_FIFO_msg(prediction)\n",
    "                os.write(fifo, msg)\n",
    "            \n",
    "            # Unprime\n",
    "            primed = False\n",
    "        \n",
    "        # Check if condition for priming has been met\n",
    "        if np.all(~event_history[0:consecutive_nonevent_reset]):\n",
    "            primed = True\n",
    "\n",
    "        k += 1\n",
    "    \n",
    "    if FIFO_filename is not None:\n",
    "        os.close(fifo)\n",
    "    \n",
    "    if store_events and store_times:\n",
    "        return predictions, predictions_timestamps, predictions_storage, classification_times\n",
    "    elif store_events:\n",
    "        return predictions, predictions_timestamps, predictions_storage\n",
    "    elif store_times:\n",
    "        return predictions, predictions_timestamps, classification_times\n",
    "    else:\n",
    "        return predictions, predictions_timestamps\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "\n",
    "We optimise the streaming algorithm in two dependent stages. The first stage is to optimise event detection by choosing the best test statistic and threshold to apply over the detection window. The test statistic will be the statistic that maximises the contrast between event and non-event regions, and the threshold will be the threshold that maximises the F-score on the training set. \n",
    "\n",
    "When our algorithm is effective at distinguishing events from non-events, we will use the optimised event detection method to optimise our classifiers on the training set. Once all classifiers are optimised, we will choose the classifier with the best accuracy on the test set based on a levenshtein distance weighted to reflect what is most desirable for its Space Invaders use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Detection TO DO\n",
    "\n",
    "\n",
    "(write lil nicer) Hypothesis from physics perspective: plotting contrast against window length we expect a peak which is the optimal point, taking the appearance of normalisation curve. Thus, two pieces of information (best metric and optimal window length) can be extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Statistic\n",
    "\n",
    "The first component to optimising event detection is to choose the best test statistic to be applied over the detection window. To do this, we first define 5 possible candidates for the test statistic. These candidates were chosen because they were deemed likely to be effective in distinguishing events from non-events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Define Test Stat Functions\n",
    "\n",
    "# due to their sine wave-like shape, events have a larger range than non-events\n",
    "def ts_range(x): \n",
    "    return np.max(x) - np.min(x)\n",
    "\n",
    "# the range but using the middle half of the distribution to reduce influence from outliers\n",
    "def ts_IQR(x): \n",
    "    return np.quantile(x, 0.75) - np.quantile(x, 0.25)\n",
    "\n",
    "# events have high peaks due to their shape compared to non-events\n",
    "def ts_abs_max(x): \n",
    "    return np.max(np.abs(x))\n",
    "\n",
    "# non-events cross the zero line (x-axis) often due to noise, \n",
    "# while events have long periods over/under the zero line\n",
    "def ts_zero_crossings(x):\n",
    "    return np.sum(x[0:-1]*x[1::] <= 0)\n",
    "\n",
    "# Fourier transforms can distinguish between events and non-events due to \n",
    "def ts_max_frequency(frame, samprate=10000):\n",
    "    fs = samprate\n",
    "    dt = 1/fs\n",
    "    t = np.arange(0, (len(frame)*dt), dt)\n",
    "    # Num samples\n",
    "    N = len(frame)\n",
    "    yf = fft(frame)\n",
    "    xf = fftfreq(N, 1/fs)\n",
    "    np.size(xf)\n",
    "    np.size(t)\n",
    "    f, t, Sxx = signal.spectrogram(frame, fs)\n",
    "    maximum = np.max(Sxx)\n",
    "    threshold = maximum/5;\n",
    "    maximum_Freqs = np.amax(Sxx, 0) # max frequency for each time\n",
    "    return np.amax(maximum_Freqs)\n",
    "\n",
    "tfn_candidates = {\"Range\": ts_range,\n",
    "                  \"IQR\": ts_IQR,\n",
    "                  \"SD\": np.std,\n",
    "                  \"Absolute Max\": ts_abs_max,\n",
    "                  \"Zero Crossings\": ts_zero_crossings,\n",
    "                  \"Fourier\": ts_max_frequency}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metric (Contrast)\n",
    "\n",
    "To choose the best test statistic from the candidates, we first calculate a series of test statistics using a sliding window over each training file. Next, we define an evaluation metric called *contrast*. Essentially, contrast is the absolute value of the Welch's t-test statistic between the set of test statistics for event regions, and the set of test statistics for non-event regions. It is defined by the following formula:\n",
    "```{math}\n",
    ":label: contrast\n",
    "\\textit{contrast}(E, E^*) = \\frac{|\\bar{E} - \\bar{E^*}|}{\\sqrt{\\frac{\\sigma_E^2}{N_E} + \\frac{\\sigma_{E^*}^2}{N_{E^*}}}}\n",
    "```\n",
    "<!-- reference it by {eq}`contrast` -->\n",
    "where $E$ is the set of test statistics calculated over event regions, $E^*$ is the non-event region test statistics, and $\\bar{k}$, $\\sigma_k$ and $N_k$ are the mean, standard deviation and number of elements in set $k$ respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def contrast(events, non_events): \n",
    "    pooled_sd = np.sqrt(np.var(events)/len(events) + np.var(non_events)/len(non_events))\n",
    "    return np.abs(np.mean(events, axis=1) - np.mean(non_events, axis=1))/pooled_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform a gridsearch varying the window length from 0 to 2 seconds and calculating the contrast of each test statistic each window length. The results are shown in {numref}`contrast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     20,
     34,
     43
    ],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_buffers_whole' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1353b1a1b9ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m def contrast_all_files(output_filename, window_size, test_stat_fns, samprate, \n\u001b[0;32m---> 45\u001b[0;31m                        waves, labels, contrast_fn, step=0.1, time_buffers=time_buffers_whole):   \n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamprate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time_buffers_whole' is not defined"
     ]
    }
   ],
   "source": [
    "def get_event_regions(wav_array, samprate, labels_dat, time_buffer):\n",
    "    before_buffer = time_buffer[0]\n",
    "    after_buffer = time_buffer[1]\n",
    "    \n",
    "    time_seq = np.linspace(1, len(wav_array), len(wav_array))/samprate\n",
    "\n",
    "    left_events_bool = np.array([False]*len(time_seq))\n",
    "    for time in labels_dat.time[labels_dat.label == \"L\"]:\n",
    "        left_events_bool = (((time_seq > time - before_buffer) & \n",
    "                             (time_seq < time+after_buffer)) | left_events_bool)\n",
    "\n",
    "    right_events_bool = np.array([False]*len(time_seq))\n",
    "    for time in labels_dat.time[labels_dat.label == \"R\"]:\n",
    "        right_events_bool = (((time_seq > time - before_buffer) & \n",
    "                              (time_seq < time + after_buffer)) | right_events_bool)\n",
    "\n",
    "    event_bool = left_events_bool | right_events_bool\n",
    "    return event_bool\n",
    "\n",
    "\n",
    "def get_test_stats(wav_array, window_size, step, test_stat_fns):\n",
    "    test_stats = np.zeros((len(test_stat_fns), len(wav_array)))\n",
    "    all_windows = np.lib.stride_tricks.sliding_window_view(wav_array, window_shape = window_size)\n",
    "    all_windows = all_windows[::step, :]\n",
    "    for i, fn in enumerate(test_stat_fns):\n",
    "        testicles = np.apply_along_axis(fn, -1, all_windows)\n",
    "        for j, teste in enumerate(testicles):\n",
    "            if j == len(testicles)-1:\n",
    "                test_stats[i, (j*step)::] = teste\n",
    "            else:\n",
    "                test_stats[i, (j*step):((j+1)*step)]  = teste\n",
    "    return test_stats\n",
    "\n",
    "\n",
    "def get_contrast(wav_array, samprate, labels_dat, window_size, step, test_stat_fns, contrast_fn, time_buffer):\n",
    "    test_stats = get_test_stats(wav_array, window_size, step, test_stat_fns)\n",
    "    events_bool = get_event_regions(wav_array, samprate, labels_dat, time_buffer)\n",
    "    event_test_stats = test_stats[:, events_bool]           \n",
    "    non_event_test_stats = test_stats[:, ~events_bool]\n",
    "    contrast_stat = contrast_fn(event_test_stats, non_event_test_stats)\n",
    "    return contrast_stat\n",
    "\n",
    "    \n",
    "def contrast_all_files(output_filename, window_size, test_stat_fns, samprate, \n",
    "                       waves, labels, contrast_fn, step=0.1, time_buffers=time_buffers_whole):   \n",
    "    step = int(step*samprate)\n",
    "    for i, key in enumerate(waves.keys()):\n",
    "        wav_array = waves[key]\n",
    "        labels_dat = labels[key]\n",
    "        \n",
    "        cont = get_contrast(wav_array, samprate, labels_dat,\n",
    "                         window_size, step, test_stat_fns,\n",
    "                         contrast_fn, time_buffers[key])\n",
    "        with open(output_filename, \"a\") as file:\n",
    "            file.write(\",\".join([str(window_size), key]) + \",\" + ','.join(np.round(cont, 4).astype(str)) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "output_filename_event_det_opt = OUT_PATH + \"event_detection_optimisation.csv\"\n",
    "\n",
    "if compute_all:\n",
    "    granularity = 100\n",
    "    open(output_filename_event_det_opt, 'w').close()    # Clears the file so that the code can be run again.\n",
    "    for i, x in enumerate(np.linspace(100, 10000, granularity)):\n",
    "        x = int(x)\n",
    "        if i%10 == 0:\n",
    "            print(f\"{i} of {granularity}\")\n",
    "        contrast_all_files(\n",
    "            output_filename_event_det_opt, \n",
    "            window_size = x, \n",
    "            test_stat_fns = tfn_candidates.values(),\n",
    "            samprate = samprate,\n",
    "            waves = waves,\n",
    "            labels = labels,\n",
    "            step = 0.1,\n",
    "            contrast_fn = contrast,\n",
    "            time_buffers = time_buffers_whole\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "contrasts = pd.read_csv(output_filename_event_det_opt, header=None)\n",
    "contrasts.columns = [\"window_size\", \"file\"] + list(tfn_candidates.keys())\n",
    "contrasts_total = contrasts.groupby(\"window_size\").mean()\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "for stat in tfn_candidates.keys():\n",
    "    plt.plot(contrasts_total.index/samprate,\n",
    "             np.abs(contrasts_total[stat]),\n",
    "             label = f\"{stat} Contrast\", alpha = 1)\n",
    "\n",
    "plt.title(\"Event Region Contrast vs. Detection Window\")\n",
    "plt.xlabel(\"Detection Window Length (s)\")\n",
    "plt.ylabel(\"Contrast (t Test Statistic)\")\n",
    "opt_det_window = contrasts_total.index[np.argmax(np.abs(contrasts_total[\"Zero Crossings\"]))]/samprate\n",
    "opt_det_window_val = np.max(np.abs(contrasts_total[\"Zero Crossings\"]))\n",
    "plt.vlines(opt_det_window, 0, opt_det_window_val,\"r\", \":\", \n",
    "           label=f\"Optimal Point ({round(opt_det_window, 2)}, {round(opt_det_window_val, 2)})\")\n",
    "plt.hlines(opt_det_window_val, 0, opt_det_window,\"r\", \":\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(OUT_PATH+\"contrast.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../report_outputs/contrast.png\n",
    "---\n",
    "scale: 75%\n",
    "name: contrast\n",
    "---\n",
    "Contrast of each test statistic as a function of window size. We can see that zero crossings produces the maximum contrast at a window length of 0.35 seconds.\n",
    "```\n",
    "<!-- reference by {numref}`contrast` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold Optimisation\n",
    "\n",
    "Now that we have determined the best test statistic and its corresponding optimal detection window length, we will use these to determine the optimal threshold for event detection. To do this, we perform yet another gridsearch to maximise $F_1$-score. The results are displayed below in {numref}`threshold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "output_filename_thresh_opt = OUT_PATH + \"threshold_optimisation.csv\"\n",
    "\n",
    "if compute_all:\n",
    "    open(output_filename_thresh_opt, \"w\").close() # Clear file\n",
    "    calibration_window_sec = 5\n",
    "    for st_scale in np.linspace(0.01, 1, 100):\n",
    "        fps, fns, tps, i = 0, 0, 0, 0\n",
    "        for key in waves.keys():\n",
    "            predictions, predictions_timestamps = streaming_classifier(\n",
    "                waves[key],\n",
    "                samprate,\n",
    "                lambda x,y: \"R\" if np.random.rand()<0.5 else \"L\",\n",
    "                input_buffer_size_sec = 0.05,\n",
    "                classification_window_size_sec = opt_det_window,\n",
    "                detection_window_size_sec = opt_det_window,\n",
    "                detection_window_offset_sec = 0,\n",
    "                calibration_window_size_sec = 5,\n",
    "                calibration_statistic_function = lambda x: ts_zero_crossings(x)/len(x),\n",
    "                event_test_statistic_function = lambda x: ts_zero_crossings(x)/len(x), \n",
    "                event_threshold_factor = st_scale, \n",
    "                flip_threshold = True, \n",
    "                consecutive_event_triggers = 3, \n",
    "                consecutive_nonevent_reset = 10 \n",
    "            )\n",
    "            before_buffer = time_buffers_hump[key][0]\n",
    "            after_buffer = time_buffers_hump[key][1]\n",
    "            actual_times = [(time-before_buffer, time+after_buffer) for time in labels[key].time]\n",
    "            actual_leftovers = deepcopy(actual_times)\n",
    "            pred_leftovers = deepcopy(predictions_timestamps)\n",
    "            tps += len(actual_times)\n",
    "            for act_times in actual_times:\n",
    "                if act_times[1] < calibration_window_sec:\n",
    "                    actual_leftovers.remove(act_times)\n",
    "                    continue\n",
    "                for pred_times in predictions_timestamps:\n",
    "                    if (act_times[0] < pred_times[1] and act_times[1] > pred_times[0] and\n",
    "                        pred_times in pred_leftovers and act_times in actual_leftovers):\n",
    "                        actual_leftovers.remove(act_times)\n",
    "                        pred_leftovers.remove(pred_times)\n",
    "            tps -= len(actual_leftovers)\n",
    "            fns += len(actual_leftovers)\n",
    "            fps += len(pred_leftovers)\n",
    "            i += 1\n",
    "        fscore = tps/(tps+0.5*(fns+fps))\n",
    "        if (st_scale*100)%10 == 0:\n",
    "            print(st_scale, fscore)\n",
    "        with open(output_filename_thresh_opt, \"a\") as file:\n",
    "            file.write(f\"{st_scale},{fscore}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "thresholds = pd.read_csv(output_filename_thresh_opt, header=None)\n",
    "thresholds.columns = [\"threshold_factor\", \"f_score\"] \n",
    "\n",
    "thresh_factors = thresholds.threshold_factor\n",
    "f_score_list = thresholds.f_score\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(thresh_factors, f_score_list)\n",
    "plt.title(\"F-Score vs. Threshold Factor\\n(Zero Crossings Calibration Statistic)\")\n",
    "opt_thresh = np.mean(thresh_factors[f_score_list == np.max(f_score_list)])\n",
    "opt_fscore = np.max(f_score_list)\n",
    "plt.vlines(opt_thresh, 0, opt_fscore, \"r\", \":\", \n",
    "           label=f\"Optimal Point ({round(opt_thresh, 2)}, {round(opt_fscore, 2)})\")\n",
    "plt.hlines(opt_fscore, 0, opt_thresh, \"r\", \":\")\n",
    "plt.xlabel(\"Threshold Factor\")\n",
    "plt.ylabel(\"F-Score\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.savefig(OUT_PATH+\"threshold.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../report_outputs/threshold.png\n",
    "---\n",
    "scale: 75%\n",
    "name: threshold\n",
    "---\n",
    "Plot of the F score for different threshold factors on the training set. The threshold is obtained by multiplying the zero crossings of the calibration window (normalised by the length of the window) by the threshold factor. We find the highest F score occurs when the threshold factor is 0.27.\n",
    "```\n",
    "<!-- reference by {numref}`threshold` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification TO DO\n",
    "\n",
    "for physics aspect just mention:\n",
    "- again, what we predict the evaluation graph should look like\n",
    "- we used a signal to filter the noise for one-three prong (mention its a physics thing to do when explaining classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     15,
     52,
     101
    ],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Prepare Classifier Candidates\n",
    "\n",
    "# catch22 kNN classifier (using stepwise selected features)\n",
    "step_csv = DEP_PATH+\"catch22_step_selected_features.csv\"\n",
    "catch22_step_training_data = pd.read_csv(step_csv)\n",
    "X_train = catch22_step_training_data.iloc[:,0:-1]\n",
    "y_labels = catch22_step_training_data.iloc[:,-1]   \n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train, y_labels)\n",
    "\n",
    "# \"Zeros\" classifier\n",
    "# returns a list of sub-arrays, grouped by the same consecutive value\n",
    "# (in this case they are groups of consecutive 1s or -1s) \n",
    "\n",
    "@njit # numba decorator that performs just-in-time (jit) compilation\n",
    "def consecutive(data, stepsize=0):                              \n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "\n",
    "# looks for the first sequence where the sign doesn't change for a period of time,\n",
    "# checks whether the average height is higher or lower than a threshold then classifies\n",
    "@njit \n",
    "def zeroes_classifier(arr, samprate, downsample_rate=10, ave_height = 10, consec_seconds = 0.2):\n",
    "    arr_ds = arr[0::downsample_rate]\n",
    "    arr_sign = np.sign(arr_ds)            \n",
    "    i = 0\n",
    "    split_arrays = consecutive(arr_sign)  \n",
    "    for sub_arr in split_arrays:\n",
    "        if len(sub_arr) > consec_seconds * samprate / downsample_rate:  # RHS converts seconds to number of samples\n",
    "            # if there were 'consec_seconds' seconds of no zero-crossings,\n",
    "            # check if the average height is bigger than 'ave_height'\n",
    "            if np.mean(arr_ds[i:(i + len(sub_arr) - 1)]) > ave_height:          \n",
    "                return 'R'\n",
    "            elif np.mean(arr_ds[i:(i + len(sub_arr) - 1)]) < -1 * ave_height:\n",
    "                return 'L'\n",
    "        i += len(sub_arr)\n",
    "    return '_'   \n",
    "\n",
    "# calculates the 5 features selected from catch22, find the 5 nearest neighbours \n",
    "# calculated using Euclidean distance, then selects the majority classification\n",
    "def catch22_knn_classifier(arr, samprate, downsample_rate=10):\n",
    "    arr_ds = arr[0::downsample_rate]\n",
    "    arr_list = arr_ds.tolist()\n",
    "    feature_one = catch22.DN_HistogramMode_5(arr_list)\n",
    "    feature_two = catch22.SB_BinaryStats_mean_longstretch1(arr_list)\n",
    "    feature_three = catch22.FC_LocalSimple_mean1_tauresrat(arr_list)\n",
    "    feature_four = catch22.DN_OutlierInclude_p_001_mdrmd(arr_list)\n",
    "    feature_five = catch22.SP_Summaries_welch_rect_area_5_1(arr_list)\n",
    "    test_features = [[feature_one, feature_two, feature_three, feature_four, feature_five]]\n",
    "    return neigh.predict(test_features)[0]                    \n",
    "\n",
    "# wave is smoothed using Savitzky-Golay Filter, then decides whether the event is\n",
    "# a left or right depending on whether the first turning point is a max or min\n",
    "def one_pronged_smoothing_classifier(arr, samprate, downsample_rate=10, window_size_seconds=0.3, max_loops=10):\n",
    "    arr_ds = arr[0::downsample_rate]\n",
    "    fs = samprate/downsample_rate\n",
    "    dt = 1/fs\n",
    "    t = np.arange(0, (len(arr_ds)*dt), dt)\n",
    "\n",
    "    # Smooth wave\n",
    "    window_length = int(window_size_seconds*samprate/downsample_rate + 1)\n",
    "    filtered_arr = signal.savgol_filter(arr_ds, window_length, 1)\n",
    "\n",
    "    # Indices of positive maxima\n",
    "    max_locs = np.array(signal.argrelextrema(filtered_arr, np.greater)[0])\n",
    "    max_vals = filtered_arr[max_locs]\n",
    "    max_locs = max_locs[max_vals > 0]\n",
    "    \n",
    "    # Indices of negative minima\n",
    "    min_locs = np.array(signal.argrelextrema(filtered_arr, np.less)[0])\n",
    "    min_vals = filtered_arr[min_locs]\n",
    "    min_locs = min_locs[min_vals < 0]\n",
    "    \n",
    "    max_min_locs = np.append(max_locs, min_locs)    # Appended indices\n",
    "    max_min_values = filtered_arr[max_min_locs]     # Values of above indices    \n",
    "    abs_max_min_values = np.abs(max_min_values)     # Absolute value of those values\n",
    "\n",
    "    # A vector with a length equal to the number of minimums: all '-1' to say minimum\n",
    "    numMin = [-1]*len(min_locs)    \n",
    "    numMax = [1]*len(max_locs)     # Same for max, but with '1'\n",
    "    isMin = np.append(numMax, numMin)\n",
    "    val_and_idx = np.vstack([abs_max_min_values, max_min_locs, isMin])\n",
    "    # Sort the magnitudes of the extrema in descending order (-1 indicates descending)\n",
    "    val_and_idx_sorted = val_and_idx[ :, (-1*val_and_idx[0]).argsort()]\n",
    "\n",
    "    if val_and_idx_sorted.shape == (3, 0):\n",
    "        if val_and_idx_sorted[2] == -1:\n",
    "            return 'L'\n",
    "        elif val_and_idx_sorted[2] == 1:\n",
    "            return 'R'\n",
    "        else:\n",
    "            return \"_\"\n",
    "    else:\n",
    "        if val_and_idx_sorted[2, 0] == -1:\n",
    "            return 'L'\n",
    "        elif val_and_idx_sorted[2, 0] == 1:\n",
    "            return 'R'\n",
    "        else:\n",
    "            return \"_\"\n",
    "\n",
    "# wave is smoothed using Savitzky-Golay Filter, then decides whether the event is\n",
    "# a left or right depending on the order of the maximum and minimum turning points\n",
    "def two_pronged_smoothing_classifier(arr, samprate, downsample_rate=10, \n",
    "                                       window_size_seconds=0.3, max_loops=10):\n",
    "    arr_ds = arr[0::downsample_rate]\n",
    "    fs = samprate/downsample_rate\n",
    "    dt = 1/fs\n",
    "    t = np.arange(0, (len(arr_ds)*dt), dt)\n",
    "\n",
    "    # Smooth wave\n",
    "    window_length = int(window_size_seconds*samprate/downsample_rate + 1)\n",
    "    filtered_arr = signal.savgol_filter(arr_ds, window_length, 1)\n",
    "\n",
    "    # Indices of positive maxima\n",
    "    max_locs = np.array(signal.argrelextrema(filtered_arr, np.greater)[0])\n",
    "    max_vals = filtered_arr[max_locs]\n",
    "    max_locs = max_locs[max_vals > 0]\n",
    "    \n",
    "    # Indices of negative minima\n",
    "    min_locs = np.array(signal.argrelextrema(filtered_arr, np.less)[0])\n",
    "    min_vals = filtered_arr[min_locs]\n",
    "    min_locs = min_locs[min_vals < 0]\n",
    "    \n",
    "    max_min_locs = np.append(max_locs, min_locs)    # Appended indices\n",
    "    max_min_values = filtered_arr[max_min_locs]     # Values of above indices    \n",
    "    abs_max_min_values = np.abs(max_min_values)     # Absolute value of those values\n",
    "\n",
    "    # A vector with a length equal to the number of minimums: all '-1' to say minimum\n",
    "    numMin = [-1]*len(min_locs)    \n",
    "    numMax = [1]*len(max_locs)     # Same for max, but with '1'\n",
    "    isMin = np.append(numMax, numMin)\n",
    "    val_and_idx = np.vstack([abs_max_min_values, max_min_locs, isMin])\n",
    "    # Sort the magnitudes of the extrema in descending order (-1 indicates descending)\n",
    "    val_and_idx_sorted = val_and_idx[ :, (-1*val_and_idx[0]).argsort()]\n",
    "    \n",
    "    # We will continue looping until we have an appropriate classification. \n",
    "    # This relies on having the extrema INTERCHANGE between max and min (no two min right next to eachother)\n",
    "    loops = 0\n",
    "    classificationFound = False\n",
    "    while not classificationFound and loops < max_loops:\n",
    "        \n",
    "        top_2 = val_and_idx_sorted[:, 0:2]             # Take the top two magnitudes\n",
    "        top_2_sorted = top_2[ :, top_2[1].argsort()]   # Sort according to the indices of those values\n",
    "        if top_2_sorted.shape != (3, 2):               # Break if we run out of turning points\n",
    "            return \"_\"\n",
    "        \n",
    "        # If two min or two max occur one after the other, \n",
    "        # we know we have an inappropriate result so we delete one of those doubled min/max\n",
    "        if top_2_sorted[2, 0]*top_2_sorted[2, 1] > 0:\n",
    "            val_and_idx_sorted = np.delete(val_and_idx_sorted, 1, 1)\n",
    "        else:\n",
    "            classificationFound = True\n",
    "        loops += 1\n",
    "    if top_2_sorted[2, 0] == -1:\n",
    "        return 'L'\n",
    "    elif top_2_sorted[2, 0] == 1:\n",
    "        return 'R'\n",
    "    else:\n",
    "        return \"_\"\n",
    "\n",
    "# finds the index of the max and min values in the wave, then classifies\n",
    "# based on whether the max or min value occurred first\n",
    "def max_min_classifier(arr, samprate, downsample_rate=10):\n",
    "    arr_ds = arr[0::downsample_rate]\n",
    "    arr_max = np.amax(arr_ds)\n",
    "    arr_min = np.amin(arr_ds)\n",
    "    max_loc = np.where(arr_ds == arr_max)[0][0]\n",
    "    min_loc = np.where(arr_ds == arr_min)[0][0]\n",
    "    if max_loc > min_loc:\n",
    "        return \"R\"\n",
    "    elif min_loc > max_loc:\n",
    "        return \"L\"\n",
    "    else:\n",
    "        return \"_\"\n",
    "\n",
    "# finds the index of the max and min values in the wave, then checks whether both\n",
    "# values are outside the range. If both are outside, then classification is based\n",
    "# on whether max or min value occurred first. Else, if only one is outside, then\n",
    "# classification is based on whether the max or min's magnitude is larger\n",
    "def max_min_range_classifier(arr, samprate, downsample_rate=10, rng = 35):\n",
    "    arr_ds = arr[0::downsample_rate]\n",
    "    arr_max = np.amax(arr_ds)\n",
    "    arr_min = np.amin(arr_ds)\n",
    "    max_loc = np.where(arr_ds == arr_max)[0][0]\n",
    "    min_loc = np.where(arr_ds == arr_min)[0][0]\n",
    "\n",
    "    if arr_max > rng and arr_min < -1 * rng:\n",
    "        if max_loc > min_loc:\n",
    "            return \"R\"\n",
    "        elif min_loc > max_loc:\n",
    "            return \"L\"\n",
    "        else:\n",
    "            return \"_\"\n",
    "    elif arr_max > rng:\n",
    "        return \"R\"\n",
    "    elif arr_min < -1 * rng:\n",
    "        return \"L\"\n",
    "    else:\n",
    "        return \"_\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Prepare classifiers for optimisation and plotting\n",
    "classifiers = {\"One-pronged\": one_pronged_smoothing_classifier,\n",
    "               \"Two-pronged\": two_pronged_smoothing_classifier,\n",
    "               \"Max-Min\": max_min_classifier,\n",
    "               \"Max-Min-Range\": max_min_range_classifier,\n",
    "               \"Zeros\": zeroes_classifier,\n",
    "               \"KNN\": catch22_knn_classifier,\n",
    "               \"Naive Random\": lambda x,y: \"R\" if np.random.rand()<0.5 else \"L\"}\n",
    "\n",
    "classifier_parameters = {\"One-pronged\": {},\n",
    "               \"Two-pronged\": {},\n",
    "               \"Max-Min\": {},\n",
    "               \"Max-Min-Range\": {\"rng\":35},\n",
    "               \"Zeros\": {\"consec_seconds\": 0.2, \"ave_height\": 0.25},\n",
    "               \"KNN\": {},\n",
    "               \"Naive Random\": {}}\n",
    "\n",
    "classifier_colours = {\"One-pronged\": \"tab:blue\",\n",
    "               \"Two-pronged\": \"tab:cyan\",\n",
    "               \"Max-Min\": \"tab:olive\",\n",
    "               \"Max-Min-Range\": \"tab:brown\",\n",
    "               \"Zeros\": \"tab:purple\",\n",
    "               \"KNN\": \"tab:pink\",\n",
    "               \"Naive Random\": \"tab:red\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def my_lev_dist(prediction, actual, sub_L_cost = 1.25, sub_R_cost = 1.25,\n",
    "                sub_under_score_cost = 0.5, delete_under_score_cost = 0,\n",
    "                delete_L_cost = 1.25, delete_R_cost = 1.25):\n",
    "    substitute_costs = np.ones((128, 128), dtype=np.float64)  \n",
    "    substitute_costs[ord('L'), ord('R')] = sub_L_cost\n",
    "    substitute_costs[ord('R'), ord('L')] = sub_R_cost\n",
    "    substitute_costs[ord('_'), ord('L')] = sub_under_score_cost\n",
    "    substitute_costs[ord('_'), ord('R')] = sub_under_score_cost\n",
    "    delete_costs = np.ones(128, dtype=np.float64)\n",
    "    delete_costs[ord('_')] = delete_under_score_cost\n",
    "    delete_costs[ord('L')] = delete_L_cost\n",
    "    delete_costs[ord('R')] = delete_R_cost\n",
    "    return lev(prediction, actual, substitute_costs = substitute_costs, delete_costs = delete_costs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "output_filename_cls_opt = OUT_PATH + \"classifier_optimisation.csv\"\n",
    "\n",
    "if compute_all:\n",
    "    open(output_filename_cls_opt, 'w').close()    # Clear the file\n",
    "\n",
    "    search_space = (2-opt_det_window)/2\n",
    "    granularity = 200\n",
    "\n",
    "    for classifier_label, classifier in classifiers.items():\n",
    "        print(classifier_label)\n",
    "        for i, w in enumerate(np.linspace(0, search_space, granularity)):\n",
    "            w = max(1e-5, w)\n",
    "            if i%(granularity//10) == 0:\n",
    "                print(f\"{i} of {granularity}\")\n",
    "            classification_window = opt_det_window+2*w\n",
    "            buffer_size = 0.05\n",
    "            for i, key in enumerate(waves):\n",
    "                predictions, predictions_timestamps = streaming_classifier(\n",
    "                    waves[key],\n",
    "                    samprate,\n",
    "                    classifier,\n",
    "                    classifier_params=classifier_parameters[classifier_label],\n",
    "                    input_buffer_size_sec = buffer_size,\n",
    "                    classification_window_size_sec = classification_window,\n",
    "                    detection_window_size_sec = opt_det_window,\n",
    "                    detection_window_offset_sec = w,\n",
    "                    calibration_window_size_sec = 5,\n",
    "                    calibration_statistic_function = lambda x: ts_zero_crossings(x)/len(x),\n",
    "                    event_test_statistic_function = lambda x: ts_zero_crossings(x)/len(x), \n",
    "                    event_threshold_factor = opt_thresh, \n",
    "                    flip_threshold = True, # Threshold is a lower bound, so true\n",
    "                    consecutive_event_triggers = 3, \n",
    "                    consecutive_nonevent_reset = 10 \n",
    "                )\n",
    "                actuals = \"\".join(labels[key].label)\n",
    "                lev_dist = my_lev_dist(predictions, actuals)\n",
    "                acc = max((len(actuals) - lev_dist), 0)/len(actuals)\n",
    "                with open(output_filename_cls_opt, \"a\") as file:\n",
    "                    file.write(\",\".join([classifier_label, str(classification_window), \n",
    "                                         key, predictions, actuals, str(lev_dist), str(acc)]) + '\\n')\n",
    "\n",
    "                    \n",
    "results = pd.read_csv(output_filename_cls_opt, header=None)\n",
    "results.columns = [\"classifier\", \"window_size\", \"file\", \"predicted\", \"actual\", \"lev_dist\", \"accuracy\"]\n",
    "results_agg = results.groupby([\"window_size\", \"classifier\"]).mean()\n",
    "results_agg.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "optimal_cl_windows = {}\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "for classifier in results.classifier.unique():\n",
    "    filt = results_agg.classifier == classifier\n",
    "    max_arg = np.argmax(signal.savgol_filter(results_agg[filt].accuracy, 15, 1))\n",
    "    max_val = np.max(signal.savgol_filter(results_agg[filt].accuracy, 15, 1))\n",
    "    optimal_cl_window = np.array(results_agg[filt].window_size)[max_arg]\n",
    "    optimal_cl_windows[classifier] = optimal_cl_window\n",
    "    \n",
    "    plt.plot(results_agg[filt].window_size, signal.savgol_filter(results_agg[filt].accuracy, 15, 1),\n",
    "             label=classifier + f\" ({round(optimal_cl_window, 2)},{round(max_val, 2)})\", \n",
    "             color=classifier_colours[classifier])\n",
    "    plt.vlines(optimal_cl_window, 0, max_val, color=classifier_colours[classifier], linestyle=\"--\", alpha=0.3)\n",
    "    \n",
    "plt.ylabel(\"Weighted Levenshtein Accuracy\")\n",
    "plt.xlabel(\"Classification Window Length (s)\")\n",
    "plt.title(\"Classifier Accuracy vs. Classification Window Length\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, 2)\n",
    "\n",
    "plt.fill_between([0, opt_det_window], 0, 1, color=\"k\", alpha = 0.2, label=\"Detection Window Lowerbound\")\n",
    "\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(OUT_PATH+\"classifier.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../report_outputs/classifier.png\n",
    "---\n",
    "scale: 75%\n",
    "name: classifier\n",
    "---\n",
    "Training accuracy of each classifier as a function of classification window length. The classification window is lower bounded by the detection window, represented by the shaded region.\n",
    "Ideally, we want to minimise window length while maximising accuracy. With this in mind, we see that the Max-Min-Range classifier has the highest accuracy at a window length equal to be the lowerbound of 0.35 seconds. This makes it the most optimal classifier by both accuracy and latency.\n",
    "```\n",
    "<!-- reference by {numref}`classifier` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classifier</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Max-Min</th>\n",
       "      <th>Max-Min-Range</th>\n",
       "      <th>Naive Random</th>\n",
       "      <th>One-pronged</th>\n",
       "      <th>Two-pronged</th>\n",
       "      <th>Zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data5</th>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data7</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.898447</td>\n",
       "      <td>0.898447</td>\n",
       "      <td>0.625747</td>\n",
       "      <td>0.898447</td>\n",
       "      <td>0.631720</td>\n",
       "      <td>0.863799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classifier       KNN   Max-Min  Max-Min-Range  Naive Random  One-pronged  \\\n",
       "File                                                                       \n",
       "data5       0.787037  0.925926       0.925926      0.574074     0.925926   \n",
       "data7       0.750000  0.870968       0.870968      0.677419     0.870968   \n",
       "Total       0.768519  0.898447       0.898447      0.625747     0.898447   \n",
       "\n",
       "Classifier  Two-pronged     Zeros  \n",
       "File                               \n",
       "data5          0.666667  0.888889  \n",
       "data7          0.596774  0.838710  \n",
       "Total          0.631720  0.863799  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_filename_tst_res = OUT_PATH + \"test_results.csv\"\n",
    "\n",
    "if compute_all:\n",
    "    open(output_filename_tst_res, 'w').close()    # Clear the file\n",
    "\n",
    "    for classifier_label, classifier in classifiers.items():\n",
    "        print(classifier_label)\n",
    "        offset = (optimal_cl_windows[classifier_label] - opt_det_window)/2\n",
    "        buffer_size = 0.05\n",
    "        for i, key in enumerate(test_waves):\n",
    "            predictions, predictions_timestamps = streaming_classifier(\n",
    "                test_waves[key],\n",
    "                samprate,\n",
    "                classifier,\n",
    "                classifier_params=classifier_parameters[classifier_label],\n",
    "                input_buffer_size_sec = buffer_size,\n",
    "                classification_window_size_sec = optimal_cl_windows[classifier_label],\n",
    "                detection_window_size_sec = opt_det_window,\n",
    "                detection_window_offset_sec = offset,\n",
    "                calibration_window_size_sec = 5,\n",
    "                calibration_statistic_function = lambda x: ts_zero_crossings(x)/len(x),\n",
    "                event_test_statistic_function = lambda x: ts_zero_crossings(x)/len(x), \n",
    "                event_threshold_factor = opt_thresh, \n",
    "                flip_threshold = True,\n",
    "                consecutive_event_triggers = 3, \n",
    "                consecutive_nonevent_reset = 10 \n",
    "            )\n",
    "            actuals = \"\".join(test_labels[key].label)\n",
    "            lev_dist = my_lev_dist(predictions, actuals)\n",
    "            acc = max((len(actuals) - lev_dist), 0)/len(actuals)\n",
    "            with open(output_filename_tst_res, \"a\") as file:\n",
    "                file.write(\",\".join([classifier_label, key, predictions, actuals, str(lev_dist), str(acc)]) + '\\n')\n",
    "\n",
    "test_results = pd.read_csv(output_filename_tst_res, header=None)\n",
    "test_results.columns = [\"Classifier\", \"File\", \"Predicted\", \"Actual\", \"Weighted Levenshtein Distance\", \"Accuracy\"]\n",
    "\n",
    "test_results = test_results.pivot(index = \"File\", columns='Classifier', values='Accuracy')\n",
    "test_results.loc['Total']= test_results.mean()\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physics Analysis Findings: TO DO\n",
    "\n",
    "Adapting the final experimental design after testing as the larger loop in the workflow suggests:\n",
    "- Calibration instead of normalisation\n",
    "- Post it notes (placed beyond 45 degrees from central viewing line)\n",
    "- Speed of eye movements (fast but no quantitative value)\n",
    "- Electrode placement (3 cm apart at least)\n",
    "- Filter\n",
    "\n",
    "Other factors that we are aware will affect the ouput:\n",
    "- blinking\n",
    "- facial movements\n",
    "\n",
    "...thus we ask users to play still, emphasising left and right movements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis finding TO DO\n",
    "\n",
    "Results for data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space Invaders!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0,
     3,
     6
    ],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def encode_msg_size(size: int) -> bytes:\n",
    "    return struct.pack(\"<I\", size)\n",
    "\n",
    "def decode_msg_size(size_bytes: bytes) -> int:\n",
    "    return struct.unpack(\"<I\", size_bytes)[0]\n",
    "\n",
    "def create_msg(content: bytes) -> bytes:\n",
    "    size = len(content)\n",
    "    return encode_msg_size(size) + content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0,
     38,
     43
    ],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_labelled_wave(wav_array, samprate, labels_dat, ax, i, title=\"\", calibration_seconds = 5, \n",
    "                       before_buffer = 1, after_buffer = 1, shade_alpha=0.2, wave_alpha=1, \n",
    "                       ymin = -512, ymax = 512):\n",
    "    time_seq = np.linspace(1, len(wav_array), len(wav_array))/samprate\n",
    "    \n",
    "    # Calibration period\n",
    "    calibration_bool = time_seq < calibration_seconds\n",
    "\n",
    "    # Get locations of events\n",
    "    left_events_bool = np.array([False]*len(time_seq))\n",
    "    for time in labels_dat.time[labels_dat.label == \"L\"]:\n",
    "        left_events_bool = ( (time_seq > time - before_buffer) & (time_seq < time+after_buffer) ) | left_events_bool\n",
    "    right_events_bool = np.array([False]*len(time_seq))\n",
    "    for time in labels_dat.time[labels_dat.label == \"R\"]:\n",
    "        right_events_bool = ( (time_seq > time - before_buffer) & (time_seq < time+after_buffer) ) | right_events_bool\n",
    "\n",
    "    # Plot wave with events\n",
    "    ax[i].plot(time_seq, wav_array, alpha=wave_alpha)\n",
    "    ax[i].fill_between(time_seq, ymax, ymin,\n",
    "                     where = left_events_bool,\n",
    "                     color = 'g',\n",
    "                     label = \"Left\",\n",
    "                     alpha=shade_alpha)\n",
    "    ax[i].fill_between(time_seq, ymax, ymin,\n",
    "                     where = right_events_bool,\n",
    "                     color = 'r',\n",
    "                     label = \"Right\",\n",
    "                     alpha=shade_alpha)\n",
    "    ax[i].fill_between(time_seq, ymax, ymin,\n",
    "                     where = calibration_bool,\n",
    "                     color = 'y',\n",
    "                     label = \"Calibration\",\n",
    "                     alpha=shade_alpha)\n",
    "    ax[i].set_title(title)\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(8, 1)\n",
    "fig.set_size_inches(16, 10)\n",
    "for i, key in enumerate(sorted(waves.keys())):\n",
    "    plot_labelled_wave(\n",
    "        waves[key], samprate, labels[key], ax, i, title=key, before_buffer = time_buffers_whole[key][0],\n",
    "        after_buffer = time_buffers_whole[key][1], shade_alpha=0.2, wave_alpha=1, ymin = -100, ymax = 100\n",
    "    )\n",
    "for i, key in enumerate(sorted(test_waves.keys())):\n",
    "    plot_labelled_wave(\n",
    "        test_waves[key], samprate, test_labels[key], ax, i+6, title=key, before_buffer = time_buffers_whole[key][0],\n",
    "        after_buffer = time_buffers_whole[key][1], shade_alpha=0.2, wave_alpha=1, ymin = -100, ymax = 100\n",
    "    )\n",
    "ax[0].legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(OUT_PATH + \"dataset_plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Final classifier used for Space Invaders\n",
    "# baudrate = 230400\n",
    "# cport = \"/dev/cu.usbserial-DJ00E33Q\"\n",
    "# ser = serial.Serial(port=cport, baudrate=baudrate)    \n",
    "# inputBufferSize = 1000   # 20000 = 1 second\n",
    "# buffer_size_sec = inputBufferSize/20000.0\n",
    "# ser.timeout = buffer_size_sec  # set read timeout 20000\n",
    "\n",
    "# classifier_label = \"One-pronged\"\n",
    "\n",
    "# print(classifier_label)\n",
    "# offset = (optimal_cl_windows[classifier_label] - opt_det_window)/2\n",
    "# buffer_size = 0.05\n",
    "# streaming_classifier(\n",
    "#     ser,\n",
    "#     samprate,\n",
    "#     classifiers[classifier_label],\n",
    "#     classifier_params=classifier_parameters[classifier_label],\n",
    "#     input_buffer_size_sec = buffer_size_sec,\n",
    "#     classification_window_size_sec = optimal_cl_windows[classifier_label],\n",
    "#     detection_window_size_sec = opt_det_window,\n",
    "#     detection_window_offset_sec = offset,\n",
    "#     calibration_window_size_sec = 5,\n",
    "#     calibration_statistic_function = lambda x: ts_zero_crossings(x)/len(x),\n",
    "#     event_test_statistic_function = lambda x: ts_zero_crossings(x)/len(x), \n",
    "#     event_threshold_factor = opt_thresh, \n",
    "#     flip_threshold = True, \n",
    "#     consecutive_event_triggers = 3, \n",
    "#     consecutive_nonevent_reset = 10,\n",
    "#     live = True,\n",
    "#     FIFO_filename = \"space_invaders_ipc\",\n",
    "#     create_FIFO_msg = None,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using backward stepwise feature selection from catch22 for kNN classifier \n",
    "\n",
    "# import decision tree classifier to model fitting and recursive feature exclusion (stepwise selection)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "KNN_DATA_PATH = \"C:/Users/David/Documents/DATA3888/Aqua10/Datasets/Good Data - Sandeep no errors/\"\n",
    "\n",
    "knn_names = ['left-middle-right-middle#2', 'left-middle-right-middle', 'left-middle-right-steph', \n",
    "            'left-middle-right-steph2', 'left-middle', 'left-right-middle-marina', 'left-right-middle-marina2', \n",
    "            'left-right-middle-marina3', 'left-right-middle-sandeep', 'right-middle']\n",
    "\n",
    "# Load the data\n",
    "knn_waves, knn_labels = load_data(\n",
    "    KNN_DATA_PATH, knn_names, scale_factor = 1, shift_factor = -512)\n",
    "\n",
    "# Define sample rate: 10,000 Hz\n",
    "samprate = 10_000\n",
    "\n",
    "# Extract events from training data\n",
    "before_buffer = 0.5\n",
    "after_buffer = 1\n",
    "    \n",
    "events = [] # list of events in terms of slice of wav_array\n",
    "event_labels = [] # list of labels\n",
    "\n",
    "for key in knn_labels:\n",
    "    wave = knn_waves[key]\n",
    "    label = knn_labels[key]\n",
    "    for lab, time in zip(label.label, label.time):\n",
    "        event_labels.append(lab)\n",
    "        event_start = int((time - before_buffer) * samprate) # in terms of sampling rate\n",
    "        event_end = int((time + after_buffer) * samprate) # in terms of sampling rate\n",
    "\n",
    "        events.append(wave[event_start:event_end])\n",
    "        \n",
    "# Compute catch22 features and convert to dataframe\n",
    "features = []\n",
    "for event in events:\n",
    "    event_ds = event[0::10] # downsample by a rate of 10\n",
    "    feature = catch22_all(event_ds)\n",
    "    features.append(feature['values'])\n",
    "\n",
    "features_df = pd.DataFrame(features)\n",
    "features_df.columns = feature['names']\n",
    "\n",
    "# fit the model\n",
    "clf = DecisionTreeClassifier(random_state=420)\n",
    "clf.fit(features_df, event_labels)\n",
    "\n",
    "# Python backward stepwise selection\n",
    "trans = RFECV(clf, cv=5)\n",
    "features_trans = trans.fit_transform(features_df, event_labels)\n",
    "\n",
    "print(features_trans.shape)\n",
    "columns_retained = features_df.iloc[:, :].columns[trans.get_support()].values\n",
    "print(columns_retained)\n",
    "\n",
    "# create df to save as csv for kNN classifier\n",
    "selected_features_df = pd.DataFrame(features_trans)\n",
    "selected_features_df.columns = columns_retained\n",
    "selected_features_df['labels'] = event_labels\n",
    "\n",
    "# selected_features_df.to_csv('catch22_step_selected_features.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "{cite}`VR`\n",
    "{cite}`SpaceInvaders`\n",
    "{cite}`BYB`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://blog.juliusschulz.de/blog/ultimate-ipython-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.368px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
