{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Space Invaders Fun and Accessible with Eye-Movement Gesture Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-imagining Space Invaders with gesture control brings with it great commercial promise. Additionally, our product can act as a learning tool to introduce individuals, particularly children, to gesture control technology; a need that will inevitably grow as gesture control becomes more integrated into our everyday lives.\n",
    "\n",
    "Using a Spiker Box from Backyard Brains {cite}`BYB`, our team performed a plethora of experiments to develop an optimal data collection strategy. We chose left and right eye movements to be the controls of our game and recorded the data with electrodes placed horizontally at an optimal spacing of 3cm. Markers were placed at -45$^\\circ$ and 45$^\\circ$ (relative to centre) to improve signal consistency. A calibration period was introduced to control for inter-subject variability.\n",
    "\n",
    "We used this data to develop a streaming algorithm. By optimising event detection and classification using a sequence of grid searches, the Max-Min-Range classifier had the best tradeoff between latency and accuracy, and hence we chose it for our product.\n",
    "\n",
    "The optimised classifier was then integrated with the Space Invaders game using inter-process communication and the prototype worked successfully.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation & Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the past two decades, profound advancements in technology such as facial recognition, gesture control, virtual assistants and other instances of machine learning have gradually been integrated into everyday life. With virtual reality worth over \\$21 billion alone {cite}`VR`, the gaming industry is evidently undergoing a similar transformation. The financial success of games such as Pokemon Go, which used augmented reality to re-develop the themes and goals of its franchise, is reason enough to design and implement a game that is similarly revamped by one of these technological advancements. \n",
    "\n",
    "This project uses gesture control, one of these technological advancements, to re-develop Space Invaders to be played with left and right eye movements. Space Invaders is an iconic 80’s game that grossed an equivalent of $13 billion {cite}`SpaceInvaders`, proving the market potential for a re-imagined version. \n",
    "\n",
    "Our target market is anyone interested in leading technologies and gaming, akin to Pokemon Go’s and the original Space Invaders audience. A short survey was conducted and out of 33 people, 85% said they would be interested in this version of Space Invaders. This demonstrates potential commercial success with a remastered launch.\n",
    "\n",
    "The fundamental aim of this project is to develop a working prototype for Space Invaders with eye control. This involves collecting data, designing and optimising a streaming classifier capable of distinguishing left and right eye movement,s and integrating this into a Space Invaders game. This becomes an arduous task if solely physics or data science undertook this project. In particular, physics is responsible for collection of representative data and data science will use this data to build and optimise a streaming classifier. Both disciplines cooperated to design an effective workflow, outlined in {numref}`flow`, to achieve the project aim. Thus, using the skills and knowledge of Physics and Data Science, a well-tested gesture controlled version of Space invaders can be developed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../report_outputs/flow.png\n",
    "---\n",
    "scale: 35%\n",
    "name: flow\n",
    "---\n",
    "Workflow diagram illustrating the process undergone by both Physics and Data Science disciplines in the re-development of the game Space Invaders.\n",
    "```\n",
    "<!-- reference by {numref}`flow` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from scipy import signal\n",
    "from copy import deepcopy\n",
    "from catch22 import catch22_all\n",
    "import catch22\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from numba import njit\n",
    "from weighted_levenshtein import lev\n",
    "import struct\n",
    "import warnings\n",
    "import serial\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Update this to point to the report folder\n",
    "PATH = \"../\"\n",
    "# To run all computation, change to True. Otherwise, precomputed files will be loaded instead.\n",
    "compute_all = False\n",
    "# If running, ensure the following line is commented out. It disables plots for knitting to html purposes. \n",
    "%matplotlib agg\n",
    "\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(420) \n",
    "# Path to outputs folder\n",
    "OUT_PATH = PATH + \"report_outputs/\"\n",
    "# Path to data\n",
    "IN_PATH = PATH + \"data/\"\n",
    "# Path to other file dependencies\n",
    "DEP_PATH = PATH + \"requirements/other_files/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(methods:exp)=\n",
    "### Experimentation & Data Collection\n",
    "\n",
    "In reference to {numref}`flow`, the first step in the re-development of Space Invaders requires designing the data collection protocol to collect data representative of the Space Invaders application. The streaming data was collected using a Backyard Brains Spikerbox {cite}`BYB`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Physical Experiments Performed\n",
    "\n",
    "We first experimented with various muscle movements, such as raising eyebrows, blinking, and smiling, and found that each generated a different signal shape. Left and right eye movements were the next investigated and produced distinguishable signals as shown in {numref}`signals`, and hence were the movements chosen for further experimentation. \n",
    "\n",
    "Left-right movement experimentation involved varying the angle and distance of the electrodes. This was shown to change the quality drastically. Furthermore, we altered the distance that the subject moved their eyes by placing physical markers at different spacings to act as targets. This also affected signal quality but improved consistency. Aditionally, we experimented with different time between movements, performing sequences in quick and slow succession. And lastly, we experimented on different subjects and investigated the inter-subject variability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(methods:findings)=\n",
    "#### Findings\n",
    "\n",
    "Left and right signals produced the most distinguishable shapes, and so were chosen as the gestures for our game. The experimental design that produced the cleanest and most consistent signals incorporated the following:\n",
    "- Electrodes spaced 3cm apart in a horizontal configuration above the eyebrow. \n",
    "- Quick eye movements at varied intervals to simulate gameplay. \n",
    "- Left and right markers placed at -45$^\\circ$ and 45$^\\circ$ relative to the middle.\n",
    "- Data was collected from more than one individual to get a representative sample. \n",
    "\n",
    "\n",
    "A calibration window was recommended to mitigate against the significant inter-subject variability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../report_outputs/movement_signals.png\n",
    "---\n",
    "scale: 90%\n",
    "name: signals\n",
    "---\n",
    "Examples of the signal shape of left and right eye movements, as well as an example of noise that we want the classifier to be robust to.\n",
    "```\n",
    "<!-- reference by {numref}`signals` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collection of Data\n",
    "By incorporating the points outlined in {ref}`methods:findings`, 8 wave files (.wav) were prepared to the following specifications:\n",
    "- 50s in length\n",
    "- First 5s is a calibration period - no movements performed\n",
    "- A sequence of left and right movements are performed for the remaining 45s at varying intervals.\n",
    "- Each file is accompanied with a labels textfile (.txt) containing the timestamps and labels of every event in the wavefile. '1' corresponds to a left eye movement, and '2' corresponds to a right eye movement.\n",
    "- Each .wav file has a range of [0, 1024], but are centred to [-512, 512] within the `load_data` function defined below.\n",
    "\n",
    "Two of the eight files were randomly selected as the test set, and the rest were assigned to the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 6 wavefiles:\n",
      "data1\n",
      "data2\n",
      "data3\n",
      "data4\n",
      "data6\n",
      "data8\n",
      "Successfully loaded 2 wavefiles:\n",
      "data5\n",
      "data7\n"
     ]
    }
   ],
   "source": [
    "def load_data(path, fnames, scale_factor = 1, shift_factor = -512, fix_alessandro=False, offsets=None):\n",
    "    waves = {}\n",
    "    labels = {}\n",
    "    for file in fnames:\n",
    "        # Load in wave file\n",
    "        samprate, wav_array = wavfile.read(path+file+\".wav\")\n",
    "        wav_array = wav_array*scale_factor\n",
    "        wav_array += shift_factor\n",
    "        # Fix the bug in alessandro's code\n",
    "        if fix_alessandro:\n",
    "            fixed_wav = []\n",
    "            step = 999\n",
    "            offset = offsets[file]\n",
    "            for j, i in enumerate(range(offset, len(wav_array)-step, step)):\n",
    "                if j == 0:\n",
    "                    fixed_wav.append(np.flip(wav_array[0:i+step]))\n",
    "                fixed_wav.append(np.flip(wav_array[i:i+step]))\n",
    "            waves[file] = np.concatenate(fixed_wav)\n",
    "        else:\n",
    "            waves[file] = wav_array\n",
    "        # Load in label file\n",
    "        labels_dat = pd.read_csv(path+file+\".txt\", sep=\",\\t\", skiprows=1)\n",
    "        labels_dat.columns = [\"label\", \"time\"]\n",
    "        labels_dat.label = [\"L\" if label == 1 else \"R\" for label in labels_dat.label]\n",
    "        labels[file] = labels_dat\n",
    "    print(f\"Successfully loaded {len(waves)} wavefiles:\")\n",
    "    print(\"\\n\".join(sorted(waves.keys())))\n",
    "    return waves, labels\n",
    "\n",
    "fnames = [\"data1\", \"data2\", \"data3\", \"data4\", \"data5\", \"data6\", \"data7\", \"data8\"]\n",
    "\n",
    "# Offsets to fix the error in alessandro's code\n",
    "offsets = {\"data1\":0,\n",
    "           \"data2\":0,\n",
    "           \"data3\":0,\n",
    "           \"data4\":0,\n",
    "           \"data5\":-5,\n",
    "           \"data6\":0,\n",
    "           \"data7\":-1,\n",
    "           \"data8\":0}\n",
    "\n",
    "# Randomly select two files for the test set, remainder as training\n",
    "test_files = np.random.choice(fnames, 2, replace=False)\n",
    "training_files = list(set(fnames) - set(test_files))\n",
    "\n",
    "# Training Data\n",
    "waves, labels = load_data(\n",
    "    IN_PATH, training_files, scale_factor = 1, shift_factor = -512, fix_alessandro=True, offsets=offsets)\n",
    "\n",
    "# Test Data\n",
    "test_waves, test_labels = load_data(\n",
    "    IN_PATH, test_files, scale_factor = 1, shift_factor = -512, fix_alessandro=True, offsets=offsets)\n",
    "\n",
    "# Define Calibration Window and Sample Rate: 10,000 Hz\n",
    "calibration_window_sec = 5\n",
    "samprate = 10_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1,
     13
    ],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Dictionaries to convert singular timestamps in the labels dataframe to \n",
    "# the time interval of the entire event and the first hump\n",
    "# First hump\n",
    "time_buffers_hump = {\n",
    "    \"data1\":(-0.3, 0.55),\n",
    "    \"data2\":(-0.3, 0.55),\n",
    "    \"data3\":(-0.3, 0.55),\n",
    "    \"data4\":(-0.5, 0.75),\n",
    "    \"data5\":(-0.5, 0.75),\n",
    "    \"data6\":(-0.5, 0.75),\n",
    "    \"data7\":(-0.5, 0.75),\n",
    "    \"data8\":(-0.5, 0.75)\n",
    "}\n",
    "\n",
    "# Whole wave\n",
    "time_buffers_whole = {\n",
    "    \"data1\":(-0.2, 1.15),\n",
    "    \"data2\":(-0.2, 1.15),\n",
    "    \"data3\":(-0.2, 1.15),\n",
    "    \"data4\":(-0.4, 1.35),\n",
    "    \"data5\":(-0.4, 1.35),\n",
    "    \"data6\":(-0.4, 1.35),\n",
    "    \"data7\":(-0.4, 1.35),\n",
    "    \"data8\":(-0.4, 1.35),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming Algorithm Design\n",
    "\n",
    "To begin the development of the classifier, we must design the basic structure of our streaming algorithm. The algorithm will consist of two parts, the first is event detection, and the second is classification. As the streaming data comes in, we will only keep a sliding window at the front of the stream in memory. This window updates in discrete intervals of some *buffer length*. We will deem this window the *classification window*. \n",
    "\n",
    "Within that classification window, a smaller window is fixed, sliding along with the classification window. This subset of the classification window is where we will test for an event, and is hence called the *detection window*. \n",
    "\n",
    "Each time the window is updated by the stream, a statistic is generated from the detection window and tested against a threshold to deterimine whether there was an event. To minimise false positives, this criterion will need to pass `consecutive_event_triggers` number of times.\n",
    "\n",
    "Once the event criterion has passed `consecutive_event_triggers` times, we pass the classification window to the classifier algorithm and block the classifier from detecting another event. When the event criterion has failed `consecutive_nonevent_reset` times, we prime the streaming algorithm to predict events again. This is to stop the algorithm from detecting the same event twice. These parameters were optimised using a gridsearch, the details of which can be found in {ref}`appendix:consecutive`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     2,
     10
    ],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Function that reads in the kth <inputBufferSize> sized segment of the array\n",
    "# Simulates streaming condition on recorded wavefiles.\n",
    "def read_arduinbro(wav_array, inputBufferSize, k):\n",
    "    if inputBufferSize*(k+1) < len(wav_array):\n",
    "        data = wav_array[(inputBufferSize*(k)):(inputBufferSize*(k+1))]\n",
    "    else:\n",
    "        data = wav_array[(inputBufferSize*(k))::]\n",
    "    return np.flip(data)\n",
    "\n",
    "\n",
    "# Streaming classifier as described above\n",
    "def streaming_classifier(\n",
    "        wav_array,                             # Either the array from file (or ser if live = True)\n",
    "        samprate,\n",
    "        classifier,\n",
    "        input_buffer_size_sec = 0.1,           # Buffer size in seconds\n",
    "        store_events = False,                  # Whether to return the classification window array for\n",
    "                                                   # debugging purposes\n",
    "        store_times = False,                   # Store time taken for each classification\n",
    "    \n",
    "        live = False,                          # If live\n",
    "        FIFO_filename = None,\n",
    "        create_FIFO_msg = None,\n",
    "        read_arduino = None,\n",
    "        process_data = None,\n",
    "\n",
    "        classifier_params = {},\n",
    "        classification_window_size_sec = 1.5,  # Total detection window [s]\n",
    "\n",
    "        calibration_window_size_sec = 5,       # The length of the calibration period to define the threshold\n",
    "        calibration_statistic_function = None, # Function that calculates the calibration statistic\n",
    "\n",
    "        detection_window_size_sec = 0.5,\n",
    "        detection_window_offset_sec = 0.5,\n",
    "        event_test_statistic_function = None,  # Function that calculates the test statistic\n",
    "        event_threshold_factor = 0.5,          # The scale factor of the calibration stat that will become\n",
    "                                                   # the threshold\n",
    "        flip_threshold = False,                # Threshold is a lower bound if true, upper bound if false\n",
    "        consecutive_event_triggers = 3,        # How many threshold triggers need to occur in a row for an \n",
    "                                                   # event to be called\n",
    "        consecutive_nonevent_reset = 10         # How many threshold failures need to occur in a row for the\n",
    "                                                   # classifier to be primed for a new event\n",
    "        ):\n",
    "\n",
    "    # Connect to fifo\n",
    "    if FIFO_filename is not None:\n",
    "        fifo = os.open(FIFO_filename, os.O_WRONLY)\n",
    "    \n",
    "    if store_events:\n",
    "        predictions_storage = []\n",
    "    if store_times:\n",
    "        classification_times = []\n",
    "    predictions = \"\"\n",
    "    predictions_timestamps = []\n",
    "\n",
    "    # Initialise variables\n",
    "    N_loops_over_window = classification_window_size_sec//input_buffer_size_sec\n",
    "    input_buffer_size = int(round(input_buffer_size_sec * samprate))\n",
    "    detection_window_offset = int(round(detection_window_offset_sec * samprate))\n",
    "    detection_window_size = int(round(detection_window_size_sec * samprate))\n",
    "    \n",
    "    # Initialise Calibration\n",
    "    calibrate = True\n",
    "    N_loops_calibration = calibration_window_size_sec//input_buffer_size_sec\n",
    "\n",
    "    # Initialise Event History\n",
    "    num_event_history = max(consecutive_event_triggers,\n",
    "                            consecutive_nonevent_reset) + 1 \n",
    "    event_history = np.array([False]*num_event_history)\n",
    "\n",
    "    # Determine length of stream\n",
    "    if live:\n",
    "        N_loops = np.inf\n",
    "    else:\n",
    "        total_time = len(wav_array)/samprate\n",
    "        N_loops = (total_time*samprate)//input_buffer_size\n",
    "\n",
    "    # Prime the classifier for new event\n",
    "    primed = True\n",
    "    \n",
    "    ### Start stream ###\n",
    "    k = 0\n",
    "    while k < N_loops:\n",
    "        if live:\n",
    "            data = read_arduino(wav_array,input_buffer_size)\n",
    "            data_temp = process_data(data)\n",
    "        else:\n",
    "            data_temp = read_arduinbro(wav_array, input_buffer_size, k)\n",
    "        if k < N_loops_over_window:\n",
    "            if k == 0:\n",
    "                data_cal = data_temp\n",
    "                data_window = data_temp\n",
    "            else:\n",
    "                data_window = np.append(data_temp, data_window)\n",
    "                if calibrate:\n",
    "                    data_cal = np.append(data_temp, data_cal)\n",
    "            k+=1\n",
    "            continue\n",
    "        else:\n",
    "            data_window = np.roll(data_window,len(data_temp))\n",
    "            data_window[0:len(data_temp)] = data_temp\n",
    "            if calibrate:\n",
    "                data_cal = np.append(data_temp,data_cal)\n",
    "                if (k > N_loops_calibration):\n",
    "                    cal_stat = calibration_statistic_function(data_cal)\n",
    "                    event_threshold = cal_stat*event_threshold_factor\n",
    "                    calibrate = False\n",
    "                k+=1\n",
    "                continue\n",
    "        # Event Detection\n",
    "        # Take detection window from classification window\n",
    "        \n",
    "        interval = data_window[detection_window_offset:(detection_window_offset + detection_window_size)] \n",
    "        test_stat = event_test_statistic_function(interval) # Calculate test stat \n",
    "                \n",
    "        # Test threshold\n",
    "        if flip_threshold:\n",
    "            is_event = (test_stat < event_threshold) \n",
    "        else:\n",
    "            is_event = (test_stat > event_threshold)\n",
    "        \n",
    "        # Record History\n",
    "        event_history[1::] = event_history[0:-1]\n",
    "        event_history[0] = is_event\n",
    "        \n",
    "        # if event, pass window to classifier\n",
    "        if np.all(event_history[0:consecutive_event_triggers]) and primed:\n",
    "            if store_times:\n",
    "                start = time.time_ns()\n",
    "            prediction = classifier(data_window, samprate, **classifier_params)\n",
    "            if store_times:\n",
    "                end = time.time_ns()\n",
    "                classification_times.append(end - start)\n",
    "            if store_events:\n",
    "                predictions_storage.append(data_window)\n",
    "                        \n",
    "            # Record prediction and time interval of event\n",
    "            predictions += prediction\n",
    "            end_time = round(k*input_buffer_size_sec, 2)\n",
    "            start_time = round(end_time - classification_window_size_sec, 2)\n",
    "            predictions_timestamps.append((start_time, end_time))\n",
    "\n",
    "            # Pipe it up\n",
    "            if FIFO_filename is not None:\n",
    "                msg = create_FIFO_msg(prediction)\n",
    "                os.write(fifo, msg)\n",
    "            \n",
    "            # Unprime\n",
    "            primed = False\n",
    "        \n",
    "        # Check if condition for priming has been met\n",
    "        if np.all(~event_history[0:consecutive_nonevent_reset]):\n",
    "            primed = True\n",
    "\n",
    "        k += 1\n",
    "    \n",
    "    if FIFO_filename is not None:\n",
    "        os.close(fifo)\n",
    "    \n",
    "    if store_events and store_times:\n",
    "        return predictions, predictions_timestamps, predictions_storage, classification_times\n",
    "    elif store_events:\n",
    "        return predictions, predictions_timestamps, predictions_storage\n",
    "    elif store_times:\n",
    "        return predictions, predictions_timestamps, classification_times\n",
    "    else:\n",
    "        return predictions, predictions_timestamps\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(methods:opt)=\n",
    "### Optimisation\n",
    "\n",
    "We optimise the streaming algorithm in two dependent stages as shown in {numref}`flow`. The first stage is to optimise event detection by choosing the best test statistic and threshold to apply over the detection window. The best test statistic will be the statistic that maximises the contrast between event and non-event regions, and the threshold will be the threshold that maximises the $F_1$-score on the training set. \n",
    "\n",
    "Once event detection is optimised, we will carry over our findings to begin optimising the classifiers using the training set. Once all classifiers are optimised, we will choose the classifier with the best accuracy on the test set based on a Levenshtein distance weighted to reflect the gaming application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event Detection\n",
    "\n",
    "<!-- \n",
    "(write lil nicer) Hypothesis from physics perspective: plotting contrast against window length we expect a peak which is the optimal point, taking the appearance of normalisation curve. Thus, two pieces of information (best metric and optimal window length) can be extracted. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Statistic\n",
    "\n",
    "The first component to optimising event detection requires choosing the best test statistic to calculate from the detection window. To do this, we first define 5 possible candidates for the test statistic. These candidates were chosen because they were deemed likely to be effective in distinguishing events from non-events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Define Test Stat Functions\n",
    "\n",
    "# due to their sine wave-like shape, events have a larger range than non-events\n",
    "def ts_range(x): \n",
    "    return np.max(x) - np.min(x)\n",
    "\n",
    "# the range but using the middle half of the distribution to reduce influence from outliers\n",
    "def ts_IQR(x): \n",
    "    return np.quantile(x, 0.75) - np.quantile(x, 0.25)\n",
    "\n",
    "# events have high peaks due to their shape compared to non-events\n",
    "def ts_abs_max(x): \n",
    "    return np.max(np.abs(x))\n",
    "\n",
    "# non-events cross the zero line (x-axis) often due to noise, \n",
    "# while events have long periods over/under the zero line\n",
    "def ts_zero_crossings(x):\n",
    "    return np.sum(x[0:-1]*x[1::] <= 0)\n",
    "\n",
    "# Fourier transforms can distinguish between events and non-events due to \n",
    "def ts_max_frequency(frame, samprate=10000):\n",
    "    fs = samprate\n",
    "    dt = 1/fs\n",
    "    t = np.arange(0, (len(frame)*dt), dt)\n",
    "    # Num samples\n",
    "    N = len(frame)\n",
    "    yf = fft(frame)\n",
    "    xf = fftfreq(N, 1/fs)\n",
    "    np.size(xf)\n",
    "    np.size(t)\n",
    "    f, t, Sxx = signal.spectrogram(frame, fs)\n",
    "    maximum = np.max(Sxx)\n",
    "    threshold = maximum/5;\n",
    "    maximum_Freqs = np.amax(Sxx, 0) # max frequency for each time\n",
    "    return np.amax(maximum_Freqs)\n",
    "\n",
    "tfn_candidates = {\"Range\": ts_range,\n",
    "                  \"IQR\": ts_IQR,\n",
    "                  \"SD\": np.std,\n",
    "                  \"Absolute Max\": ts_abs_max,\n",
    "                  \"Zero Crossings\": ts_zero_crossings}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Maximising Contrast\n",
    "\n",
    "To choose the best test statistic from the candidates, we first calculate a series of test statistics using a sliding window over each training file. Next, we define an evaluation metric called *contrast*. Essentially, contrast is the absolute value of the Welch's t-test statistic between the set of test statistics for event regions, and the set of test statistics for non-event regions. It is defined in {eq}`contrast`:\n",
    "```{math}\n",
    ":label: contrast\n",
    "\\textit{contrast}(E, E^*) = \\frac{|\\bar{E} - \\bar{E^*}|}{\\sqrt{\\frac{\\sigma_E^2}{N_E} + \\frac{\\sigma_{E^*}^2}{N_{E^*}}}}\n",
    "```\n",
    "<!-- reference it by {eq}`contrast` -->\n",
    "where $E$ is the set of test statistics calculated over event regions, $E^*$ is the non-event region test statistics, and $\\bar{k}$, $\\sigma_k$ and $N_k$ are the mean, standard deviation and number of elements in set $k$ respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def contrast(events, non_events): \n",
    "    pooled_sd = np.sqrt(np.var(events)/len(events) + np.var(non_events)/len(non_events))\n",
    "    return np.abs(np.mean(events, axis=1) - np.mean(non_events, axis=1))/pooled_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform a gridsearch varying the window length from 0s to 2s and calculating the contrast of each candidate statistic for each window length. The results are shown in {numref}`contrast`. The best test statistic can be seen to be 'zero crossings' with an optimal detection window length of 0.43s. Zero crossings is defined in {eq}`zeros`.\n",
    "\n",
    "```{math}\n",
    ":label: zeros\n",
    "\\text{Z}(\\mathbf{x}) = \\frac{\\sum_{i=1}^{n-1} \\text{min}\\left(\\text{sign}(x_i\\times x_{i+1}), 0\\right)}{n}\n",
    "```\n",
    "<!-- reference it by {eq}`zeros` -->\n",
    "Where $\\mathbf{x}$ is the detection window with $n$ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def get_event_regions(wav_array, samprate, labels_dat, time_buffer):\n",
    "    before_buffer = time_buffer[0]\n",
    "    after_buffer = time_buffer[1]\n",
    "    \n",
    "    time_seq = np.linspace(1, len(wav_array), len(wav_array))/samprate\n",
    "\n",
    "    left_events_bool = np.array([False]*len(time_seq))\n",
    "    for time in labels_dat.time[labels_dat.label == \"L\"]:\n",
    "        left_events_bool = (((time_seq > time - before_buffer) & \n",
    "                             (time_seq < time+after_buffer)) | left_events_bool)\n",
    "\n",
    "    right_events_bool = np.array([False]*len(time_seq))\n",
    "    for time in labels_dat.time[labels_dat.label == \"R\"]:\n",
    "        right_events_bool = (((time_seq > time - before_buffer) & \n",
    "                              (time_seq < time + after_buffer)) | right_events_bool)\n",
    "\n",
    "    event_bool = left_events_bool | right_events_bool\n",
    "    return event_bool\n",
    "\n",
    "\n",
    "def get_test_stats(wav_array, window_size, step, test_stat_fns):\n",
    "    test_stats = np.zeros((len(test_stat_fns), len(wav_array)))\n",
    "    all_windows = np.lib.stride_tricks.sliding_window_view(wav_array, window_shape = window_size)\n",
    "    all_windows = all_windows[::step, :]\n",
    "    for i, fn in enumerate(test_stat_fns):\n",
    "        testicles = np.apply_along_axis(fn, -1, all_windows)\n",
    "        for j, teste in enumerate(testicles):\n",
    "            if j == len(testicles)-1:\n",
    "                test_stats[i, (j*step)::] = teste\n",
    "            else:\n",
    "                test_stats[i, (j*step):((j+1)*step)]  = teste\n",
    "    return test_stats\n",
    "\n",
    "\n",
    "def get_contrast(wav_array, samprate, labels_dat, window_size, step, test_stat_fns, contrast_fn, time_buffer):\n",
    "    test_stats = get_test_stats(wav_array, window_size, step, test_stat_fns)\n",
    "    events_bool = get_event_regions(wav_array, samprate, labels_dat, time_buffer)\n",
    "    event_test_stats = test_stats[:, events_bool]           \n",
    "    non_event_test_stats = test_stats[:, ~events_bool]\n",
    "    contrast_stat = contrast_fn(event_test_stats, non_event_test_stats)\n",
    "    return contrast_stat\n",
    "\n",
    "    \n",
    "def contrast_all_files(file, window_size, test_stat_fns, samprate, \n",
    "                       waves, labels, contrast_fn, step=0.1, time_buffers=time_buffers_whole):   \n",
    "    step = int(step*samprate)\n",
    "    for i, key in enumerate(waves.keys()):\n",
    "        wav_array = waves[key]\n",
    "        labels_dat = labels[key]\n",
    "        \n",
    "        cont = get_contrast(wav_array, samprate, labels_dat,\n",
    "                         window_size, step, test_stat_fns,\n",
    "                         contrast_fn, time_buffers[key])\n",
    "        \n",
    "        file.write(\",\".join([str(window_size), key]) + \",\" + ','.join(np.round(cont, 4).astype(str)) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "output_filename_event_det_opt = OUT_PATH + \"event_detection_optimisation.csv\"\n",
    "\n",
    "if compute_all:\n",
    "    granularity = 100\n",
    "    open(output_filename_event_det_opt, 'w').close()    # Clears the file so that the code can be run again.\n",
    "    with open(output_filename_event_det_opt, \"a\") as file:\n",
    "        for i, x in enumerate(np.linspace(100, 10000, granularity)):\n",
    "            x=int(x)\n",
    "            print(x)\n",
    "            contrast_all_files(\n",
    "                file, \n",
    "                window_size = x, \n",
    "                test_stat_fns = tfn_candidates.values(),\n",
    "                samprate = samprate,\n",
    "                waves = waves,\n",
    "                labels = labels,\n",
    "                step = 0.1,\n",
    "                contrast_fn = contrast,\n",
    "                time_buffers = time_buffers_whole\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "contrasts = pd.read_csv(output_filename_event_det_opt, header=None)\n",
    "contrasts.columns = [\"window_size\", \"file\"] + list(tfn_candidates.keys())\n",
    "contrasts_total = contrasts.groupby(\"window_size\").mean()\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "for stat in tfn_candidates.keys():\n",
    "    plt.plot(contrasts_total.index/samprate,\n",
    "             np.abs(contrasts_total[stat]),\n",
    "             label = f\"{stat} Contrast\", alpha = 1)\n",
    "\n",
    "plt.title(\"Event Region Contrast vs. Detection Window\")\n",
    "plt.xlabel(\"Detection Window Length (s)\")\n",
    "plt.ylabel(\"Contrast (Welch's t-Test Statistic)\")\n",
    "opt_det_window = contrasts_total.index[np.argmax(np.abs(contrasts_total[\"Zero Crossings\"]))]/samprate\n",
    "opt_det_window_val = np.max(np.abs(contrasts_total[\"Zero Crossings\"]))\n",
    "plt.vlines(opt_det_window, 0, opt_det_window_val,\"r\", \":\", \n",
    "           label=f\"Optimal Point ({round(opt_det_window, 2)}, {round(opt_det_window_val, 2)})\")\n",
    "plt.hlines(opt_det_window_val, 0, opt_det_window,\"r\", \":\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(OUT_PATH+\"contrast.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../report_outputs/contrast.png\n",
    "---\n",
    "scale: 75%\n",
    "name: contrast\n",
    "---\n",
    "Contrast of each test statistic as a function of window size. The contrast is calculated using {eq}`contrast`. We can see that zero crossings {eq}`zeros` produces the maximum contrast at a window length of 0.43s.\n",
    "```\n",
    "<!-- reference by {numref}`contrast` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Threshold Optimisation\n",
    "\n",
    "Now that we have determined the best test statistic and its corresponding optimal detection window length, we will use these to determine the optimal threshold for event detection. To do this, we perform yet another gridsearch to maximise $F_1$-score. Instead of searching for the threshold, we instead search for a factor $f$ which is used to define the threshold using {eq}`thresh`. This was recommended by the physics team in {ref}`methods:findings`. \n",
    "\n",
    "\n",
    "```{math}\n",
    ":label: thresh\n",
    "t = f\\times \\text{Z}(\\mathbf{c})\n",
    "```\n",
    "<!-- reference it by {eq}`thresh` -->\n",
    "\n",
    "Where $t$ is the threshold, $f$ is the threshold factor, Z is defined in {eq}`zeros` and $\\mathbf{c}$ is the calibration window.\n",
    "\n",
    "We have used the $F_1$-score to determine the performance of the event detection as it weighs the false positives and false negatives equally. Both false positives and false negatives are undesirable for our application: a false positive would mean an involuntary movement and a false negative would a missed movement, both scenarios endanger the player's spaceship. $F_1$-score is defined in {eq}`f1`.\n",
    "\n",
    "```{math}\n",
    ":label: f1\n",
    "F_1 = \\frac{\\text{TP}}{\\text{TP}+\\frac{1}{2}(\\text{FP} + \\text{FN})}\n",
    "```\n",
    "<!-- reference it by {eq}`f1` -->\n",
    "\n",
    "The results of the gridsearch are displayed below in {numref}`threshold`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "output_filename_thresh_opt = OUT_PATH + \"threshold_optimisation.csv\"\n",
    "\n",
    "if compute_all:\n",
    "    with open(output_filename_thresh_opt, \"w\") as file: # Clear file\n",
    "        for st_scale in np.linspace(0.01, 1, 100):\n",
    "            fps, fns, tps, i = 0, 0, 0, 0\n",
    "            for key in waves.keys():\n",
    "                predictions, predictions_timestamps = streaming_classifier(\n",
    "                    waves[key],\n",
    "                    samprate,\n",
    "                    lambda x,y: \"R\" if np.random.rand()<0.5 else \"L\",\n",
    "                    input_buffer_size_sec = 0.05,\n",
    "                    classification_window_size_sec = opt_det_window,\n",
    "                    detection_window_size_sec = opt_det_window,\n",
    "                    detection_window_offset_sec = 0,\n",
    "                    calibration_window_size_sec = calibration_window_sec,\n",
    "                    calibration_statistic_function = lambda x: ts_zero_crossings(x)/len(x),\n",
    "                    event_test_statistic_function = lambda x: ts_zero_crossings(x)/len(x), \n",
    "                    event_threshold_factor = st_scale, \n",
    "                    flip_threshold = True, \n",
    "                    consecutive_event_triggers = 3, \n",
    "                    consecutive_nonevent_reset = 10 \n",
    "                )\n",
    "                before_buffer = time_buffers_hump[key][0]\n",
    "                after_buffer = time_buffers_hump[key][1]\n",
    "                actual_times = [(t-before_buffer, t+after_buffer) for t in labels[key].time]\n",
    "                actual_leftovers = deepcopy(actual_times)\n",
    "                pred_leftovers = deepcopy(predictions_timestamps)\n",
    "                tps += len(actual_times)\n",
    "                for act_times in actual_times:\n",
    "                    if act_times[1] < calibration_window_sec:\n",
    "                        actual_leftovers.remove(act_times)\n",
    "                        continue\n",
    "                    for pred_times in predictions_timestamps:\n",
    "                        if (act_times[0] < pred_times[1] and act_times[1] > pred_times[0] and\n",
    "                            pred_times in pred_leftovers and act_times in actual_leftovers):\n",
    "                            actual_leftovers.remove(act_times)\n",
    "                            pred_leftovers.remove(pred_times)\n",
    "                tps -= len(actual_leftovers)\n",
    "                fns += len(actual_leftovers)\n",
    "                fps += len(pred_leftovers)\n",
    "                i += 1\n",
    "            fscore = tps/(tps+0.5*(fns+fps))\n",
    "            if (st_scale*100)%10 == 0:\n",
    "                print(st_scale, fscore)\n",
    "            file.write(f\"{st_scale},{fscore}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "thresholds = pd.read_csv(output_filename_thresh_opt, header=None)\n",
    "thresholds.columns = [\"threshold_factor\", \"f_score\"] \n",
    "\n",
    "thresh_factors = thresholds.threshold_factor\n",
    "f_score_list = thresholds.f_score\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(thresh_factors, f_score_list)\n",
    "plt.title(\"$F_1$-Score vs. Threshold Factor\\n for Zero Crossings\")\n",
    "opt_thresh = np.mean(thresh_factors[f_score_list == np.max(f_score_list)])\n",
    "opt_fscore = np.max(f_score_list)\n",
    "plt.vlines(opt_thresh, 0, opt_fscore, \"r\", \":\", \n",
    "           label=f\"Optimal Point ({round(opt_thresh, 2)}, {round(opt_fscore, 2)})\")\n",
    "plt.hlines(opt_fscore, 0, opt_thresh, \"r\", \":\")\n",
    "plt.xlabel(\"Threshold Factor\")\n",
    "plt.ylabel(\"$F_1$-Score\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.savefig(OUT_PATH+\"threshold.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../report_outputs/threshold.png\n",
    "---\n",
    "scale: 75%\n",
    "name: threshold\n",
    "---\n",
    "Plot of the $F_1$-score for different threshold factors on the training set. The threshold is obtained by {eq}`thresh`. We find the highest $F_1$-score occurs when the threshold factor is 0.33.\n",
    "```\n",
    "<!-- reference by {numref}`threshold` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifiers\n",
    "\n",
    "Now that the event detection has been optimised, we must now optimise classification. To do this, the data science team developed five classifiers, each aiming to capture a different distinguishing feature identified by the physics team in their investigations {ref}`methods:exp`. In particular, *One Extrema* applies a Savitzky-Golay filter, as per the physicists' recommendations in {ref}`methods:findings`, and looks to identify whether the first turning point is a maximum (R) or minimum (L). *Two Extrema* does the same, but looks for a max followed by a min (R) or vice versa (L). *Max-Min* essentially does the same as *Two Extrema* but without filtering. *Max-Min-Range* applies a correction to *Max-Min* so that it only considers a point to be a maximum or minimum when it is above a certain threshold distance from the origin, governed by the `rng` parameter. The optimisation of this parameter can be found in {ref}`appendix:maxminrange`. Additionally, we developed a knn classifier, the optimisation of which can be found in {ref}`appendix:knn`. Finally, we implement a naive classifer for a baseline, which randomly predicts an event as either L or R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Prepare Classifier Candidates\n",
    "\n",
    "# catch22 kNN classifier (using stepwise selected features)\n",
    "step_csv = DEP_PATH+\"catch22_step_selected_features.csv\"\n",
    "catch22_step_training_data = pd.read_csv(step_csv)\n",
    "X_train = catch22_step_training_data.iloc[:,0:-1]\n",
    "y_labels = catch22_step_training_data.iloc[:,-1]   \n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train, y_labels)\n",
    "\n",
    "\n",
    "# calculates the 5 features selected from catch22, find the 5 nearest neighbours \n",
    "# calculated using Euclidean distance, then selects the majority classification\n",
    "def catch22_knn_classifier(arr, samprate, downsample_rate=10):\n",
    "    arr_ds = arr[0::downsample_rate]\n",
    "    arr_list = arr_ds.tolist()\n",
    "    feature_one = catch22.DN_HistogramMode_5(arr_list)\n",
    "    feature_two = catch22.SB_BinaryStats_mean_longstretch1(arr_list)\n",
    "    feature_three = catch22.FC_LocalSimple_mean1_tauresrat(arr_list)\n",
    "    feature_four = catch22.DN_OutlierInclude_p_001_mdrmd(arr_list)\n",
    "    feature_five = catch22.SP_Summaries_welch_rect_area_5_1(arr_list)\n",
    "    test_features = [[feature_one, feature_two, feature_three, feature_four, feature_five]]\n",
    "    return neigh.predict(test_features)[0]                    \n",
    "\n",
    "# wave is smoothed using Savitzky-Golay Filter, then decides whether the event is\n",
    "# a left or right depending on whether the first turning point is a max or min\n",
    "def one_extrema_smoothing_classifier(arr, samprate, downsample_rate=10, window_size_seconds=0.3, max_loops=10):\n",
    "    arr_ds = arr[0::downsample_rate]\n",
    "    fs = samprate/downsample_rate\n",
    "    dt = 1/fs\n",
    "    t = np.arange(0, (len(arr_ds)*dt), dt)\n",
    "\n",
    "    # Smooth wave\n",
    "    window_length = int(window_size_seconds*samprate/downsample_rate + 1)\n",
    "    filtered_arr = signal.savgol_filter(arr_ds, window_length, 1)\n",
    "\n",
    "    # Indices of positive maxima\n",
    "    max_locs = np.array(signal.argrelextrema(filtered_arr, np.greater)[0])\n",
    "    max_vals = filtered_arr[max_locs]\n",
    "    max_locs = max_locs[max_vals > 0]\n",
    "    \n",
    "    # Indices of negative minima\n",
    "    min_locs = np.array(signal.argrelextrema(filtered_arr, np.less)[0])\n",
    "    min_vals = filtered_arr[min_locs]\n",
    "    min_locs = min_locs[min_vals < 0]\n",
    "    \n",
    "    max_min_locs = np.append(max_locs, min_locs)    # Appended indices\n",
    "    max_min_values = filtered_arr[max_min_locs]     # Values of above indices    \n",
    "    abs_max_min_values = np.abs(max_min_values)     # Absolute value of those values\n",
    "\n",
    "    # A vector with a length equal to the number of minimums: all '-1' to say minimum\n",
    "    numMin = [-1]*len(min_locs)    \n",
    "    numMax = [1]*len(max_locs)     # Same for max, but with '1'\n",
    "    isMin = np.append(numMax, numMin)\n",
    "    val_and_idx = np.vstack([abs_max_min_values, max_min_locs, isMin])\n",
    "    # Sort the magnitudes of the extrema in descending order (-1 indicates descending)\n",
    "    val_and_idx_sorted = val_and_idx[ :, (-1*val_and_idx[0]).argsort()]\n",
    "\n",
    "    if val_and_idx_sorted.shape == (3, 0):\n",
    "        if val_and_idx_sorted[2] == -1:\n",
    "            return 'L'\n",
    "        elif val_and_idx_sorted[2] == 1:\n",
    "            return 'R'\n",
    "        else:\n",
    "            return \"_\"\n",
    "    else:\n",
    "        if val_and_idx_sorted[2, 0] == -1:\n",
    "            return 'L'\n",
    "        elif val_and_idx_sorted[2, 0] == 1:\n",
    "            return 'R'\n",
    "        else:\n",
    "            return \"_\"\n",
    "\n",
    "# wave is smoothed using Savitzky-Golay Filter, then decides whether the event is\n",
    "# a left or right depending on the order of the maximum and minimum turning points\n",
    "def two_extrema_smoothing_classifier(arr, samprate, downsample_rate=10, \n",
    "                                       window_size_seconds=0.3, max_loops=10):\n",
    "    arr_ds = arr[0::downsample_rate]\n",
    "    fs = samprate/downsample_rate\n",
    "    dt = 1/fs\n",
    "    t = np.arange(0, (len(arr_ds)*dt), dt)\n",
    "\n",
    "    # Smooth wave\n",
    "    window_length = int(window_size_seconds*samprate/downsample_rate + 1)\n",
    "    filtered_arr = signal.savgol_filter(arr_ds, window_length, 1)\n",
    "\n",
    "    # Indices of positive maxima\n",
    "    max_locs = np.array(signal.argrelextrema(filtered_arr, np.greater)[0])\n",
    "    max_vals = filtered_arr[max_locs]\n",
    "    max_locs = max_locs[max_vals > 0]\n",
    "    \n",
    "    # Indices of negative minima\n",
    "    min_locs = np.array(signal.argrelextrema(filtered_arr, np.less)[0])\n",
    "    min_vals = filtered_arr[min_locs]\n",
    "    min_locs = min_locs[min_vals < 0]\n",
    "    \n",
    "    max_min_locs = np.append(max_locs, min_locs)    # Appended indices\n",
    "    max_min_values = filtered_arr[max_min_locs]     # Values of above indices    \n",
    "    abs_max_min_values = np.abs(max_min_values)     # Absolute value of those values\n",
    "\n",
    "    # A vector with a length equal to the number of minimums: all '-1' to say minimum\n",
    "    numMin = [-1]*len(min_locs)    \n",
    "    numMax = [1]*len(max_locs)     # Same for max, but with '1'\n",
    "    isMin = np.append(numMax, numMin)\n",
    "    val_and_idx = np.vstack([abs_max_min_values, max_min_locs, isMin])\n",
    "    # Sort the magnitudes of the extrema in descending order (-1 indicates descending)\n",
    "    val_and_idx_sorted = val_and_idx[ :, (-1*val_and_idx[0]).argsort()]\n",
    "    \n",
    "    # We will continue looping until we have an appropriate classification. \n",
    "    # This relies on having the extrema INTERCHANGE between max and min (no two min right next to eachother)\n",
    "    loops = 0\n",
    "    classificationFound = False\n",
    "    while not classificationFound and loops < max_loops:\n",
    "        \n",
    "        top_2 = val_and_idx_sorted[:, 0:2]             # Take the top two magnitudes\n",
    "        top_2_sorted = top_2[ :, top_2[1].argsort()]   # Sort according to the indices of those values\n",
    "        if top_2_sorted.shape != (3, 2):               # Break if we run out of turning points\n",
    "            return \"_\"\n",
    "        \n",
    "        # If two min or two max occur one after the other, \n",
    "        # we know we have an inappropriate result so we delete one of those doubled min/max\n",
    "        if top_2_sorted[2, 0]*top_2_sorted[2, 1] > 0:\n",
    "            val_and_idx_sorted = np.delete(val_and_idx_sorted, 1, 1)\n",
    "        else:\n",
    "            classificationFound = True\n",
    "        loops += 1\n",
    "    if top_2_sorted[2, 0] == -1:\n",
    "        return 'L'\n",
    "    elif top_2_sorted[2, 0] == 1:\n",
    "        return 'R'\n",
    "    else:\n",
    "        return \"_\"\n",
    "\n",
    "# finds the index of the max and min values in the wave, then classifies\n",
    "# based on whether the max or min value occurred first\n",
    "def max_min_classifier(arr, samprate, downsample_rate=10):\n",
    "    arr_ds = arr[0::downsample_rate]\n",
    "    arr_max = np.amax(arr_ds)\n",
    "    arr_min = np.amin(arr_ds)\n",
    "    max_loc = np.where(arr_ds == arr_max)[0][0]\n",
    "    min_loc = np.where(arr_ds == arr_min)[0][0]\n",
    "    if max_loc > min_loc:\n",
    "        return \"R\"\n",
    "    elif min_loc > max_loc:\n",
    "        return \"L\"\n",
    "    else:\n",
    "        return \"_\"\n",
    "\n",
    "# finds the index of the max and min values in the wave, then checks whether both\n",
    "# values are outside the range. If both are outside, then classification is based\n",
    "# on whether max or min value occurred first. Else, if only one is outside, then\n",
    "# classification is based on whether the max or min's magnitude is larger\n",
    "@njit\n",
    "def max_min_range_classifier(arr, samprate, downsample_rate=10, rng = 35):\n",
    "    arr_ds = arr[0::downsample_rate]\n",
    "    arr_max = np.amax(arr_ds)\n",
    "    arr_min = np.amin(arr_ds)\n",
    "    max_loc = np.where(arr_ds == arr_max)[0][0]\n",
    "    min_loc = np.where(arr_ds == arr_min)[0][0]\n",
    "\n",
    "    if arr_max > rng and arr_min < -1 * rng:\n",
    "        if max_loc > min_loc:\n",
    "            return \"R\"\n",
    "        elif min_loc > max_loc:\n",
    "            return \"L\"\n",
    "        else:\n",
    "            return \"_\"\n",
    "    elif arr_max > rng:\n",
    "        return \"R\"\n",
    "    elif arr_min < -1 * rng:\n",
    "        return \"L\"\n",
    "    else:\n",
    "        return \"_\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Prepare classifiers for optimisation and plotting\n",
    "classifiers = {\"One-Extrema\": one_extrema_smoothing_classifier,\n",
    "               \"Two-Extrema\": two_extrema_smoothing_classifier,\n",
    "               \"Max-Min\": max_min_classifier,\n",
    "               \"Max-Min-Range\": max_min_range_classifier,\n",
    "               \"KNN\": catch22_knn_classifier,\n",
    "               \"Naive Random\": lambda x,y: \"R\" if np.random.rand()<0.5 else \"L\"}\n",
    "\n",
    "classifier_parameters = {\"One-Extrema\": {},\n",
    "               \"Two-Extrema\": {},\n",
    "               \"Max-Min\": {},\n",
    "               \"Max-Min-Range\": {\"rng\":35},\n",
    "               \"KNN\": {},\n",
    "               \"Naive Random\": {}}\n",
    "\n",
    "classifier_colours = {\"One-Extrema\": \"tab:blue\",\n",
    "               \"Two-Extrema\": \"tab:cyan\",\n",
    "               \"Max-Min\": \"tab:olive\",\n",
    "               \"Max-Min-Range\": \"tab:brown\",\n",
    "               \"KNN\": \"tab:pink\",\n",
    "               \"Naive Random\": \"tab:red\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy Metric\n",
    "\n",
    "To estimate the accuracy of our classifier, we have opted to use weighted Levenshtein distance. The Levenshtein distance measures the minimum number of deletions, insertions or replacements required to transform one sequence into the other. Our metric weighs replacements and deletions more heavily than insertions, counting a replacement and a deletion as 1.25 and insertions as 0.5. When playing the game, a misclassification (fixed by replacement) would be quite costly, as the game would be doing the opposite of the instruction given. A false positive event (fixed by a deletion) where it detects an event when no instruction was given would also be costly. In contrast, a missed event (fixed by an insertion) is far less costly as the player can simply redo the eye movement. This justifies using the weighted Levenshtein distance to calculate accuracy. Once the weighted Levenshtein distance is calculated, the accuracy is computed using {eq}`lev`: \n",
    "\n",
    "```{math}\n",
    ":label: lev\n",
    "a = \\frac{l-D_{lv}}{l}\n",
    "```\n",
    "<!-- reference it by {eq}`lev` -->\n",
    "\n",
    "where $a$ is the accuracy, $l$ is the length of the actual sequence and $D_{lv}$ is the weighted Levenshtein distance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def my_lev_dist(prediction, actual, sub_L_cost = 1.25, sub_R_cost = 1.25,\n",
    "                sub_under_score_cost = 0.5, delete_under_score_cost = 0,\n",
    "                delete_L_cost = 1.25, delete_R_cost = 1.25):\n",
    "    substitute_costs = np.ones((128, 128), dtype=np.float64)  \n",
    "    substitute_costs[ord('L'), ord('R')] = sub_L_cost\n",
    "    substitute_costs[ord('R'), ord('L')] = sub_R_cost\n",
    "    substitute_costs[ord('_'), ord('L')] = sub_under_score_cost\n",
    "    substitute_costs[ord('_'), ord('R')] = sub_under_score_cost\n",
    "    delete_costs = np.ones(128, dtype=np.float64)\n",
    "    delete_costs[ord('_')] = delete_under_score_cost\n",
    "    delete_costs[ord('L')] = delete_L_cost\n",
    "    delete_costs[ord('R')] = delete_R_cost\n",
    "    return lev(prediction, actual, substitute_costs = substitute_costs, delete_costs = delete_costs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Latency Analysis\n",
    "\n",
    "The actual time taken for each algorithm to classify is negligible when compared to the time taken for the classificaiton window to come in (see {ref}`appendix:time` for more information). This means the lag is dominated by the length of the classification window. Hence, the accuracy defined in {eq}`lev` must be balanced with a minimum classification window length to optimise the classifier's performance.\n",
    "\n",
    "\n",
    "##### Classifier Optimisation\n",
    "\n",
    "Once the metric has been defined, a series of grid searches were performed for classifier to optimise the classification window size. Using the detection window as a base, an extension was applied on either side of the detection window to slowly widen the classification window. This extension was varied from 0s to 1.65s in increments of 0.00825s and the accuracy at each step is shown in {numref}`classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "output_filename_cls_opt = OUT_PATH + \"classifier_optimisation.csv\"\n",
    "\n",
    "if compute_all:\n",
    "    open(output_filename_cls_opt, 'w').close()    # Clear the file\n",
    "\n",
    "    search_space = (2-opt_det_window)/2\n",
    "    granularity = 200\n",
    "\n",
    "    for classifier_label, classifier in classifiers.items():\n",
    "        print(classifier_label)\n",
    "        for i, w in enumerate(np.linspace(0, search_space, granularity)):\n",
    "            w = max(1e-5, w)\n",
    "            if i%(granularity//10) == 0:\n",
    "                print(f\"{i} of {granularity}\")\n",
    "            classification_window = opt_det_window+2*w\n",
    "            buffer_size = 0.05\n",
    "            for i, key in enumerate(waves):\n",
    "                predictions, predictions_timestamps = streaming_classifier(\n",
    "                    waves[key],\n",
    "                    samprate,\n",
    "                    classifier,\n",
    "                    classifier_params=classifier_parameters[classifier_label],\n",
    "                    input_buffer_size_sec = buffer_size,\n",
    "                    classification_window_size_sec = classification_window,\n",
    "                    detection_window_size_sec = opt_det_window,\n",
    "                    detection_window_offset_sec = w,\n",
    "                    calibration_window_size_sec = calibration_window_sec,\n",
    "                    calibration_statistic_function = lambda x: ts_zero_crossings(x)/len(x),\n",
    "                    event_test_statistic_function = lambda x: ts_zero_crossings(x)/len(x), \n",
    "                    event_threshold_factor = opt_thresh, \n",
    "                    flip_threshold = True, # Threshold is a lower bound, so true\n",
    "                    consecutive_event_triggers = 3, \n",
    "                    consecutive_nonevent_reset = 10 \n",
    "                )\n",
    "                actuals = \"\".join(labels[key].label)\n",
    "                lev_dist = my_lev_dist(predictions, actuals)\n",
    "                acc = max((len(actuals) - lev_dist), 0)/len(actuals)\n",
    "                with open(output_filename_cls_opt, \"a\") as file:\n",
    "                    file.write(\",\".join([classifier_label, str(classification_window), \n",
    "                                         key, predictions, actuals, str(lev_dist), str(acc)]) + '\\n')\n",
    "                    \n",
    "results = pd.read_csv(output_filename_cls_opt, header=None)\n",
    "results.columns = [\"classifier\", \"window_size\", \"file\", \"predicted\", \"actual\", \"lev_dist\", \"accuracy\"]\n",
    "results_agg = results.groupby([\"window_size\", \"classifier\"]).mean()\n",
    "results_agg.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "optimal_cl_windows = {}\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "for classifier in results.classifier.unique():\n",
    "    filt = results_agg.classifier == classifier\n",
    "    max_arg = np.argmax(signal.savgol_filter(results_agg[filt].accuracy, 15, 1))\n",
    "    max_val = np.max(signal.savgol_filter(results_agg[filt].accuracy, 15, 1))\n",
    "    optimal_cl_window = np.array(results_agg[filt].window_size)[max_arg]\n",
    "    optimal_cl_windows[classifier] = optimal_cl_window\n",
    "    \n",
    "    plt.plot(results_agg[filt].window_size, signal.savgol_filter(results_agg[filt].accuracy, 15, 1),\n",
    "             label=classifier + f\" ({round(optimal_cl_window, 2)},{min(round(max_val, 2), 1.0)})\", \n",
    "             color=classifier_colours[classifier])\n",
    "    plt.vlines(optimal_cl_window, 0, max_val, color=classifier_colours[classifier], linestyle=\"--\", alpha=0.3)\n",
    "    \n",
    "plt.ylabel(\"Weighted Levenshtein Accuracy\")\n",
    "plt.xlabel(\"Classification Window Length (s)\")\n",
    "plt.title(\"Classifier Accuracy vs. Classification Window Length\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, 2)\n",
    "\n",
    "plt.fill_between([0, opt_det_window], 0, 1, color=\"k\", alpha = 0.2, label=\"Detection Window Lowerbound\")\n",
    "\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(OUT_PATH+\"classifier.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../report_outputs/classifier.png\n",
    "---\n",
    "scale: 75%\n",
    "name: classifier\n",
    "---\n",
    "Training accuracy of each classifier as a function of classification window length. The classification window is lower bounded by the detection window, represented by the shaded region.\n",
    "Ideally, we want to minimise window length while maximising accuracy. With this in mind, we see that the Max-Min-Range classifier has the highest accuracy at a window length equal to be the lowerbound of 0.43s. This makes it the most optimal classifier by both accuracy and latency.\n",
    "```\n",
    "<!-- reference by {numref}`classifier` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "Now that we have optimised each classifier using the training set, we must assess each classifier's out-of-sample performance. To do this, we calculate the average accuracy on the test set. We found that Max-Min had the highest accuracy of 90% with a window size of 1.23s, closely followed by Max-Min-Range at 88% with a window size of 0.43s (the full results can be found in {ref}`appendix:test`). \n",
    "\n",
    "Since Max-Min-Range has good accuracy with a significantly lower window size, we choose it as the classifier to deploy within our game.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "output_filename_tst_res = OUT_PATH + \"test_results.csv\"\n",
    "\n",
    "if compute_all:\n",
    "    open(output_filename_tst_res, 'w').close()    # Clear the file\n",
    "\n",
    "    for classifier_label, classifier in classifiers.items():\n",
    "        print(classifier_label)\n",
    "        offset = (optimal_cl_windows[classifier_label] - opt_det_window)/2\n",
    "        buffer_size = 0.05\n",
    "        for i, key in enumerate(test_waves):\n",
    "            predictions, predictions_timestamps = streaming_classifier(\n",
    "                test_waves[key],\n",
    "                samprate,\n",
    "                classifier,\n",
    "                classifier_params=classifier_parameters[classifier_label],\n",
    "                input_buffer_size_sec = buffer_size,\n",
    "                classification_window_size_sec = optimal_cl_windows[classifier_label],\n",
    "                detection_window_size_sec = opt_det_window,\n",
    "                detection_window_offset_sec = offset,\n",
    "                calibration_window_size_sec = calibration_window_sec,\n",
    "                calibration_statistic_function = lambda x: ts_zero_crossings(x)/len(x),\n",
    "                event_test_statistic_function = lambda x: ts_zero_crossings(x)/len(x), \n",
    "                event_threshold_factor = opt_thresh, \n",
    "                flip_threshold = True,\n",
    "                consecutive_event_triggers = 3, \n",
    "                consecutive_nonevent_reset = 10 \n",
    "            )\n",
    "            actuals = \"\".join(test_labels[key].label)\n",
    "            lev_dist = my_lev_dist(predictions, actuals)\n",
    "            acc = max((len(actuals) - lev_dist), 0)/len(actuals)\n",
    "            with open(output_filename_tst_res, \"a\") as file:\n",
    "                file.write(\",\".join([classifier_label, key, predictions, actuals, str(lev_dist), str(acc)]) + '\\n')\n",
    "\n",
    "test_results = pd.read_csv(output_filename_tst_res, header=None)\n",
    "test_results.columns = [\"Classifier\", \"File\", \"Predicted\", \"Actual\", \"Weighted Levenshtein Distance\", \"Accuracy\"]\n",
    "\n",
    "test_results = test_results.pivot(index = \"File\", columns='Classifier', values='Accuracy')\n",
    "\n",
    "top_accs = test_results.mean().sort_values(ascending=False)\n",
    "top = test_results.mean().sort_values(ascending=False).index\n",
    "top_windows = [optimal_cl_windows[k] for k in test_results.mean().sort_values(ascending=False).index]\n",
    "\n",
    "top_df = pd.DataFrame()\n",
    "\n",
    "top_df[\"Classifier\"] = top\n",
    "top_df[\"Accuracy\"] = np.round(np.array(top_accs), 2)\n",
    "top_df[\"Window Length (s)\"] = np.round(np.array(top_windows), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of results\n",
    "\n",
    "After experimenting with different methods of data collection, we found the best data collection method involved spacing the electrodes 3cm apart. Furthermore, performing quick movements produced the clearest signal and limiting movements to left and right simplified the classifier so that we could effectively achieve the aim.\n",
    "\n",
    "Using the data collected, we found the optimal test statistic was zero crossings at a detection window size of 0.43s with a threshold factor was 0.33, show in {numref}`contrast` and {numref}`threshold`. We decided to use the Max-Min-Range classifier with a classification window size equal to the aforementioned detection window. We chose this classifier because of its excellent performance in both accuracy and latency, which will make our game accurate and responsive.\n",
    "\n",
    "Finally, to integrate the classifier into Space Invaders, we adapted a team member’s existing Java implementation into Python. The optimised Max-Min-Range classifier was then merged with the game. Despite both working well independently, the combined product was initially quite laggy. This was resolved by running the classifier and game separately and having them interact via inter-process communication. Details of the deployment can be found in {ref}`appendix:deployment`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, the Spike Recorder software was used to record the training dataset. However, the data was drastically different when transitioning to live data from Python. Both the threshold and shape of the signals varied between the two. This led to us executing the entire pipeline outlined in {numref}`flow` again with new data recorded directly from Python. \n",
    "\n",
    "The data obtained from the Python software had a tendency to be volatile as the random noise varied greatly with different people. This was solved by the physicists recommendation of a calibration period; having the player keep their eyes still for 5s at the start of play. This allowed us to define the threshold more robustly using {eq}`thresh`. Additionally, some classifiers aimed to address noise by using a Savitzky-Golay filter.\n",
    "\n",
    "Latency was a major problem in the initial stages of this project. There was a significant time delay between the eye movement and the `streaming_classifier` function being able to classify the eye movement. This was overcome by significantly reducing the window size. Additionally, when running the `streaming_classifier` function and the game in one file, we encountered significant lag. We resolved this by separating the function and the game into different files, running them simultaneously and interfacing them using inter-process communication detailed in {ref}`appendix:deployment`.\n",
    "\n",
    "We focused on optimising the core mechanics of left and right eye movements. In future, additional features could be added to the game such as blinking or muscle movements to implement controlled shooting. Multiplayer could also be implemented in a similar way. Making the game a self-contained application would also improve the ease of use for a consumer market. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this project, physics and data science disciplines collaborated to achieve the aim of developing prototype of gesture-controlled Space Invaders. By developing and evaluating numerous classifiers using curated data from the physicists, we were able to develop a fast and accurate classifier for use in a functioning game. Due to the time restrictions, we were limited in the amount of controls we were able to implement, having only left and right eye movements. However, we aspire to develop future upgrades to the game. These include having user-inputted shooting executed by another control such as blinks or muscle movements and creating a multiplayer option. Despite the challenging nature of this project, we were able to combine data science and physics expertise to develop a very successful final product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions\n",
    "\n",
    "Student 490423356 was responsible for editing the given python streaming code to save the input as a wav file, and automate logging the time keys were pressed during data collection (key presses were used to signal the event an eye movement). They aided in the construction and implementation of physical experiments to determine the most appropriate final experimental design.They implemented an event detection method which uses Fourier transforms, that was evaluated by the group in the test statistic graphical analysis. They performed research on six different types of normalisation techniques that could be used for preprocessing an input signal. Some of these were transformed into event detection statistics, such as Z-Score. They additionally proposed the idea to have a calibration period, which the group agreed is a better method to generalise the signal for all users rather than normalisation. They designed and implemented an adaptation of the existing two and three extrema classifiers, to make them more robust to unexpected changes in the signal. This student wrote the speech for the final presentation. They were also responsible for organising meeting times and having the PowerPoint ready for each Monday presentation (with help from other group members).\n",
    "\n",
    "Student 490413128: Wrote the Max-Min classifier and the Max-Min-Range classifier. Significantly contributed to writing the code for the evaluation. Researched and implemented Inter-Process Communication. Collected a lot of data. Contributed significantly to writing the discussion section. Helped in writing the methods section. Wrote the results section of the report. Rewrote the executive summary so that the report fell within the word limit. Helped in creating the Powerpoint for each Monday presentation.\n",
    "\n",
    "480366780 contributed to this project through generating reliable and robust data that was used to evaluate the accuracy of the classifiers. They worked on finding distinct signals that we were able to be incorporated as the controls of the game. They evaluated the optimal positioning of the electrodes and distance the eye must move to generate the clearest and most noticeable signals. They created a survey that allowed us to gain a better understanding of the public’s interest towards our project which also helped shape our motivation. They helped with implementing Fourier transforms as an alternative option for event detection and aided in the research of using pipes. They created the slides for the final presentation, helped write the speech and wrote parts of the final report. They also helped research Inter-Process Communication. \n",
    "\n",
    "Student 490155963 contributed to this project by converting the Space Invaders he had from Java into Python. He also helped with recording some of the data. He was the primary team member working on merging the classifier and game together, and reducing the lag the combined product was producing. He implemented the classifier on the game with the help of a pipe data processing structure.\n",
    "\n",
    "Student 490388088 contributed to this project by exploring a machine-learning alternative to the rule-based classifiers the other data science members made. He explored how to use catch22, performed feature selection, and created a k-nearest neighbours classifier to complement the other classifiers. He also made great contributions to the editing of the report to ensure it flowed and well represented the project as a whole.\n",
    "\n",
    "Student 480380144: Developed the structure for our streaming classifier, translating it from R. Also designed the data science pipeline to optimise our classifiers. This involved designing and performing experiments to optimise for each of the parameters in the streaming classifier, specifically detection and classification window lengths. Additionally, they played a key role in writing our report, despite breaking their hand two weeks from the due date which meant they could only work effectively on it a few days out from the due date. Their report contributions included setting up Jupyter Book and interlacing the sections with the code for reproducibility. Overall, their most important contribution was providing direction to our group. By laying out the experimental pipeline, it allowed all group members to contribute to the final product more effectively.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(appendix:deployment)=\n",
    "### Space Invaders Deployment Code\n",
    "\n",
    "Below is the final classifier used in the game, as well as a link to the game itself and the functions used to connect the two with inter-process communication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     1,
     7
    ],
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Code for inter-process communication between the game and the classifier.\n",
    "def encode_msg_size(size: int) -> bytes:\n",
    "    return struct.pack(\"<I\", size)\n",
    "\n",
    "def create_msg(content: bytes) -> bytes:\n",
    "    size = len(content)\n",
    "    return encode_msg_size(size) + content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Functions for Serial\n",
    "def read_arduino(ser,inputBufferSize):\n",
    "#     data = ser.readline((inputBufferSize+1)*2)\n",
    "    data = ser.read((inputBufferSize+1)*2)\n",
    "    out =[(int(data[i])) for i in range(0,len(data))]\n",
    "    return out\n",
    "\n",
    "def process_data(data):\n",
    "    data_in = np.array(data)\n",
    "    result = []\n",
    "    i = 1\n",
    "    while i < len(data_in)-1:\n",
    "        if data_in[i] > 127:\n",
    "            # Found beginning of frame\n",
    "            # Extract one sample from 2 bytes\n",
    "            intout = (np.bitwise_and(data_in[i],127))*128\n",
    "            i = i + 1\n",
    "            intout = intout + data_in[i]\n",
    "            result = np.append(result,intout)\n",
    "        i=i+1\n",
    "    return np.flip(np.array(result)-512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Final classifier used for Space Invaders\n",
    "\n",
    "# Connect to spiker box - change to match port\n",
    "# cport = \"/dev/cu.usbserial-DJ00E33Q\"\n",
    "# baudrate = 230400\n",
    "# ser = serial.Serial(port=cport, baudrate=baudrate)    \n",
    "# inputBufferSize = 1000   # 20000 = 1 second\n",
    "# buffer_size_sec = inputBufferSize/20000.0\n",
    "# ser.timeout = buffer_size_sec  # set read timeout 20000\n",
    "\n",
    "# classifier_label = \"Max-Min-Range\"\n",
    "# offset = (optimal_cl_windows[classifier_label] - opt_det_window)/2\n",
    "# buffer_size = 0.05\n",
    "# streaming_classifier(\n",
    "#     ser,\n",
    "#     samprate,\n",
    "#     classifiers[classifier_label],\n",
    "#     classifier_params=classifier_parameters[classifier_label],\n",
    "#     input_buffer_size_sec = buffer_size_sec,\n",
    "#     classification_window_size_sec = optimal_cl_windows[classifier_label],\n",
    "#     detection_window_size_sec = opt_det_window,\n",
    "#     detection_window_offset_sec = offset,\n",
    "#     calibration_window_size_sec = calibration_window_sec,\n",
    "#     calibration_statistic_function = lambda x: ts_zero_crossings(x)/len(x),\n",
    "#     event_test_statistic_function = lambda x: ts_zero_crossings(x)/len(x), \n",
    "#     event_threshold_factor = opt_thresh, \n",
    "#     flip_threshold = True, \n",
    "#     consecutive_event_triggers = 3, \n",
    "#     consecutive_nonevent_reset = 10,\n",
    "#     live = True,\n",
    "#     FIFO_filename = \"space_invaders_ipc\",\n",
    "#     create_FIFO_msg = create_msg,\n",
    "#     read_arduino = read_arduino,\n",
    "#     process_data = process_data\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game can be found in the Space_Invaders subfolder within the report folder. To run the game, run space_invaders.py in one terminal, and run the code defined above in another **in that order**. You will need to ensure the Spiker Box is connected to the correct port via the Serial python package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(appendix:test)=\n",
    "### Test Set Accuracies\n",
    "Below are the accuracies for all classifiers on the test set, along with their optimal window sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Window Length (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Max-Min</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Max-Min-Range</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One-Extrema</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two-Extrema</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Random</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classifier  Accuracy  Window Length (s)\n",
       "0        Max-Min      0.90               1.23\n",
       "1  Max-Min-Range      0.88               0.43\n",
       "2    One-Extrema      0.85               0.81\n",
       "3            KNN      0.78               0.51\n",
       "4    Two-Extrema      0.70               1.06\n",
       "5   Naive Random      0.61               1.76"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(appendix:time)=\n",
    "### Latency Analysis\n",
    "\n",
    "Below is the plot showing how long each classifier took to classify every event in the training set. Since the order of magnitude is milliseconds, this justifies focusing on minimising window length as that is of order seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "buffer_size_sec = 0.05\n",
    "all_classification_times = {}\n",
    "better_all_classification_times = {}\n",
    "for classifier_label, classifier in classifiers.items():\n",
    "    start = time.time()\n",
    "    for i, key in enumerate(waves):\n",
    "        predictions, predictions_timestamps, times = streaming_classifier(\n",
    "            waves[key],\n",
    "            samprate,\n",
    "            classifiers[classifier_label],\n",
    "            classifier_params=classifier_parameters[classifier_label],\n",
    "            input_buffer_size_sec = buffer_size_sec,\n",
    "            classification_window_size_sec = opt_det_window,\n",
    "            detection_window_size_sec = opt_det_window,\n",
    "            detection_window_offset_sec = 0,\n",
    "            calibration_window_size_sec = 5,\n",
    "            calibration_statistic_function = lambda x: ts_zero_crossings(x)/len(x),\n",
    "            event_test_statistic_function = lambda x: ts_zero_crossings(x)/len(x), \n",
    "            event_threshold_factor = opt_thresh, \n",
    "            flip_threshold = True, \n",
    "            store_times = True,\n",
    "            consecutive_event_triggers = 3, \n",
    "            consecutive_nonevent_reset = 10,\n",
    "            live = False,\n",
    "        )\n",
    "\n",
    "        if classifier_label in better_all_classification_times.keys():\n",
    "            better_all_classification_times[classifier_label] += times\n",
    "\n",
    "        else:\n",
    "            better_all_classification_times[classifier_label] = times\n",
    "\n",
    "\n",
    "        if \"times\" in all_classification_times.keys():\n",
    "            all_classification_times[\"times\"].append(times)\n",
    "            all_classification_times[\"classifier\"].append(classifier_label)\n",
    "        else:\n",
    "            all_classification_times[\"times\"] = []\n",
    "            all_classification_times[\"classifier\"] = []\n",
    "            all_classification_times[\"times\"].append(times)\n",
    "            all_classification_times[\"classifier\"].append(classifier_label)\n",
    "        \n",
    "for key, val in better_all_classification_times.items():\n",
    "    better_all_classification_times[key] = np.array(val)/1e6\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(better_all_classification_times.values(), labels = better_all_classification_times.keys())\n",
    "plt.ylabel(\"Time Taken (ms)\")\n",
    "plt.xlabel(\"Classifier\")\n",
    "plt.title(\"Time Taken to Classify Each Event (Classification Window Length of 0.43s)\")\n",
    "plt.savefig(OUT_PATH+\"classifier_times.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![times](../report_outputs/classifier_times.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(appendix:consecutive)=\n",
    "### Triggers and Reset Optimisation\n",
    "\n",
    "Below is the gridsearch used to optimise `consecutive_event_triggers` and `consecutive_nonevent_reset`. We chose the minimum pair with optimal f score of 0.993 - (3, 10). A minimum pair minimises latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [],
    "tags": [
     "hide-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Gridsearch to optimise consecutive_event_triggers and consecutive_nonevent_reset\n",
    "# Chose minimum pair with optimal f score of 0.993 - (3, 10). A minimum pair minimises latency\n",
    "if compute_all:\n",
    "    trigset = {}\n",
    "    for trigs in range(1, 6):\n",
    "        for reset in range(5, 25):\n",
    "            fscores = []\n",
    "            for key in waves.keys():\n",
    "                fps, fns, tps, i = 0, 0, 0, 0\n",
    "                predictions, predictions_timestamps = streaming_classifier(\n",
    "                    waves[key],\n",
    "                    samprate,\n",
    "                    lambda x,y: \"R\" if np.random.rand()<0.5 else \"L\",\n",
    "                    input_buffer_size_sec = 0.05,\n",
    "                    classification_window_size_sec = opt_det_window,\n",
    "                    detection_window_size_sec = opt_det_window,\n",
    "                    detection_window_offset_sec = 0,\n",
    "                    calibration_window_size_sec = calibration_window_sec,\n",
    "                    calibration_statistic_function = lambda x: ts_zero_crossings(x)/len(x),\n",
    "                    event_test_statistic_function = lambda x: ts_zero_crossings(x)/len(x), \n",
    "                    event_threshold_factor = 0.33, \n",
    "                    flip_threshold = True, \n",
    "                    consecutive_event_triggers = trigs, \n",
    "                    consecutive_nonevent_reset = reset\n",
    "                )\n",
    "                before_buffer = time_buffers_hump[key][0]\n",
    "                after_buffer = time_buffers_hump[key][1]\n",
    "                actual_times = [(time-before_buffer, time+after_buffer) for time in labels[key].time]\n",
    "                actual_leftovers = deepcopy(actual_times)\n",
    "                pred_leftovers = deepcopy(predictions_timestamps)\n",
    "                tps += len(actual_times)\n",
    "                for act_times in actual_times:\n",
    "                    if act_times[1] < calibration_window_sec:\n",
    "                        actual_leftovers.remove(act_times)\n",
    "                        continue\n",
    "                    for pred_times in predictions_timestamps:\n",
    "                        if (act_times[0] < pred_times[1] and act_times[1] > pred_times[0] and\n",
    "                            pred_times in pred_leftovers and act_times in actual_leftovers):\n",
    "                            actual_leftovers.remove(act_times)\n",
    "                            pred_leftovers.remove(pred_times)\n",
    "                tps -= len(actual_leftovers)\n",
    "                fns += len(actual_leftovers)\n",
    "                fps += len(pred_leftovers)\n",
    "                i += 1\n",
    "                fscore = tps/(tps+0.5*(fns+fps))\n",
    "                fscores.append(fscore)\n",
    "            print(trigs, reset, np.mean(fscores))\n",
    "            trigset[(trigs, reset)] = np.mean(fscores)\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(appendix:knn)=\n",
    "### KNN Optimisation\n",
    "\n",
    "Below is the code used to perform feature selection on the features calculated using catch22 for the kNN classifier. An external set of data was used to determine these features as to not bias the optimisation process undertaken in {ref}`methods:opt`.\n",
    "This feature data was saved to `catch22_step_selected_features.csv` for use in the kNN classifier. The method undertaken to perform feature selection is described in {cite}`kaggle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "hide-input",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 10 wavefiles:\n",
      "left-middle\n",
      "left-middle-right-middle\n",
      "left-middle-right-middle#2\n",
      "left-middle-right-steph\n",
      "left-middle-right-steph2\n",
      "left-right-middle-marina\n",
      "left-right-middle-marina2\n",
      "left-right-middle-marina3\n",
      "left-right-middle-sandeep\n",
      "right-middle\n",
      "(215, 5)\n",
      "['DN_HistogramMode_5' 'SB_BinaryStats_mean_longstretch1'\n",
      " 'FC_LocalSimple_mean1_tauresrat' 'DN_OutlierInclude_p_001_mdrmd'\n",
      " 'SP_Summaries_welch_rect_area_5_1']\n"
     ]
    }
   ],
   "source": [
    "# Using backward stepwise feature selection from catch22 for kNN classifier \n",
    "\n",
    "# import decision tree classifier to model fitting and recursive feature exclusion (stepwise selection)\n",
    "\n",
    "KNN_DATA_PATH = IN_PATH + \"KNN/\"\n",
    "\n",
    "knn_names = ['left-middle-right-middle#2', 'left-middle-right-middle', 'left-middle-right-steph', \n",
    "            'left-middle-right-steph2', 'left-middle', 'left-right-middle-marina', 'left-right-middle-marina2', \n",
    "            'left-right-middle-marina3', 'left-right-middle-sandeep', 'right-middle']\n",
    "\n",
    "# Load the data\n",
    "knn_waves, knn_labels = load_data(\n",
    "    KNN_DATA_PATH, knn_names, scale_factor = 1, shift_factor = -512, fix_alessandro=False)\n",
    "\n",
    "# Define sample rate: 10,000 Hz\n",
    "samprate = 10_000\n",
    "\n",
    "# Extract events from training data\n",
    "before_buffer = 0.5\n",
    "after_buffer = 1\n",
    "    \n",
    "events = [] # list of events in terms of slice of wav_array\n",
    "event_labels = [] # list of labels\n",
    "\n",
    "for key in knn_labels:\n",
    "    wave = knn_waves[key]\n",
    "    label = knn_labels[key]\n",
    "    for lab, t in zip(label.label, label.time):\n",
    "        event_labels.append(lab)\n",
    "        event_start = int((t - before_buffer) * samprate) # in terms of sampling rate\n",
    "        event_end = int((t + after_buffer) * samprate) # in terms of sampling rate\n",
    "\n",
    "        events.append(wave[event_start:event_end])\n",
    "        \n",
    "# Compute catch22 features and convert to dataframe\n",
    "features = []\n",
    "for event in events:\n",
    "    event_ds = event[0::10] # downsample by a rate of 10\n",
    "    feature = catch22_all(event_ds)\n",
    "    features.append(feature['values'])\n",
    "\n",
    "features_df = pd.DataFrame(features)\n",
    "features_df.columns = feature['names']\n",
    "\n",
    "# fit the model\n",
    "clf = DecisionTreeClassifier(random_state=420)\n",
    "clf.fit(features_df, event_labels)\n",
    "\n",
    "# Python backward stepwise selection\n",
    "trans = RFECV(clf, cv=5)\n",
    "features_trans = trans.fit_transform(features_df, event_labels)\n",
    "\n",
    "print(features_trans.shape)\n",
    "columns_retained = features_df.iloc[:, :].columns[trans.get_support()].values\n",
    "print(columns_retained)\n",
    "\n",
    "# create df to save as csv for kNN classifier\n",
    "selected_features_df = pd.DataFrame(features_trans)\n",
    "selected_features_df.columns = columns_retained\n",
    "selected_features_df['labels'] = event_labels\n",
    "\n",
    "# selected_features_df.to_csv(DEP_PATH+'catch22_step_selected_features.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(appendix:maxminrange)=\n",
    "### Max-Min-Range Optimisation\n",
    "The following code performs a grid search to optimise the `rng` threshold for the Max-Min-Range classifier. The `rng` threshold is varied from 0 to 100 in increments of 1, and the corresponding weighted Levenshtein accuracies are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "hide-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "classifiers1 = {\"Max-Min-Range\": max_min_range_classifier}\n",
    "\n",
    "file_accuracies = {}\n",
    "\n",
    "buffer_size_sec = 0.05\n",
    "\n",
    "if compute_all:\n",
    "    for classifier_label, classifier in classifiers1.items():\n",
    "        #offset = (optimal_cl_windows[classifier_label] - opt_det_window)/2\n",
    "        print(classifier_label)\n",
    "        for range_threshold in np.linspace(0, 100, 101):\n",
    "            print(\"\\nCurrent Range Threshold:\", range_threshold)\n",
    "\n",
    "            current_accuracies = []\n",
    "            for i, key in enumerate(waves):\n",
    "                \n",
    "                predictions, predictions_timestamps = streaming_classifier(\n",
    "                    waves[key],\n",
    "                    samprate,\n",
    "                    classifiers[classifier_label],\n",
    "                    classifier_params={\"rng\" : range_threshold},\n",
    "                    input_buffer_size_sec = buffer_size_sec,\n",
    "                    classification_window_size_sec = opt_det_window,  #opt_det_window + 0.01\n",
    "                    detection_window_size_sec = opt_det_window,       #opt_det_window\n",
    "                    detection_window_offset_sec = 0,   #offset ^ uncomment it above\n",
    "                    calibration_window_size_sec = 5,\n",
    "                    calibration_statistic_function = lambda x: ts_zero_crossings(x)/len(x),\n",
    "                    event_test_statistic_function = lambda x: ts_zero_crossings(x)/len(x), \n",
    "                    event_threshold_factor = 0.33,          #opt_thresh \n",
    "                    flip_threshold = True, \n",
    "                    consecutive_event_triggers = 3, \n",
    "                    consecutive_nonevent_reset = 10,\n",
    "                    live = False,\n",
    "                )\n",
    "                actuals = \"\".join(labels[key].label)\n",
    "\n",
    "                lev_dist = my_lev_dist(actuals, predictions)\n",
    "                acc = abs(len(actuals) - lev_dist)/len(actuals)\n",
    "                current_accuracies.append(acc)\n",
    "            if range_threshold in file_accuracies:\n",
    "                file_accuracies[range_threshold] += current_accuracies\n",
    "            else:\n",
    "                file_accuracies[range_threshold] = current_accuracies\n",
    "\n",
    "\n",
    "    ave_accuracies_per_range_val = {}\n",
    "    for range_thresh, acc_each_file_ls in file_accuracies.items():\n",
    "        ave_accuracies_per_range_val[range_thresh] = sum(acc_each_file_ls) / len(acc_each_file_ls)\n",
    "    print(\"done\")\n",
    "\n",
    "    best_ranges = []\n",
    "    best_value = 0\n",
    "    for acc in ave_accuracies_per_range_val.values():\n",
    "        if round(acc, 5) > round(best_value, 5):  #need to round because python maintains its floats very imprecisly\n",
    "            best_value = acc\n",
    "\n",
    "    for key, value in ave_accuracies_per_range_val.items():\n",
    "        if round(value, 5) == round(best_value, 5):\n",
    "            best_ranges.append(key)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(ave_accuracies_per_range_val.keys(), ave_accuracies_per_range_val.values())\n",
    "    if len(best_ranges) > 1:\n",
    "        plt.vlines(best_ranges[0], 0, best_value, linestyle=\":\", label=f\"Best Ranges: {round(best_ranges[0], 2)} to {round(best_ranges[len(best_ranges) - 1], 2)}, Accuracy = {round        (best_value, 2)}\")\n",
    "        plt.vlines(best_ranges[len(best_ranges) - 1], 0, best_value, linestyle=\":\")\n",
    "        plt.axvspan(best_ranges[0], best_ranges[len(best_ranges) - 1], alpha=0.1, color='red')\n",
    "    else:\n",
    "        plt.vlines(best_ranges[0], 0, best_value, linestyle=\":\", label=f\"Best Range: {round(best_ranges[0], 2)}, Accuracy = {round(best_value, 2)}\")\n",
    "\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.ylabel(\"Weighted Levenshtein Accuracy\")\n",
    "    plt.xlabel(\"Range Threshold\")\n",
    "    plt.title(\"Classifier Accuracy vs. Range Threshold for Window Size of 0.46 Seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "The following python packages were used in this report: Numpy {cite}`numpy`, Pandas {cite}`pandas`, Scipy {cite}`scipy`, matplotlib {cite}`plot`, catch22 {cite}`catch22`, sci-kit learn {cite}`sklearn`, numba {cite}`numba`, levdist {cite}`levdist`, and pyserial {cite}`serial`\n",
    "\n",
    "\n",
    "```{bibliography}\n",
    ":all:\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "c4dc433831b506e0d25481c84a652fa4d2aed8e252441e22b25d2076b86b7e5b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.344px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
